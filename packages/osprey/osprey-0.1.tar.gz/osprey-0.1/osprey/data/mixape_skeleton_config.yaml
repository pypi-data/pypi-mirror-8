# osprey configuration file.
#---------------------------
# usage:
#  osprey worker condif.yaml

estimator:
    # The model/estimator to be fit. This can be specified in one of three
    # ways: either by loading a pickle file which contains a serialized
    # estimator, an importable entry point, or a string which is parsed via
    # eval().

    pickle: my-model.pkl            # path to a file

    entry_point: mixtape.tica.tICA  # importable python class/instances

    eval: |
        Pipeline([
                ('featurizer', DihedralFeaturizer(types=['phi', 'psi'])),
                ('tica', tICA(n_components=4)),
                ('cluster', MiniBatchKMeans()),
                ('msm', MarkovStateModel(n_timescales=5, verbose=False)),
        ])

    __eval_globals__: osprey.plugins.mixtape.eval_globals  # (default)
    # when the string above is eval()d, the context is preloaded with mixtape
    # classes (e.g. tICA, MarkovStateModel, etc). This is controlled by the
    # function specified in `__eval_globals__`. The
    # `osprey.plugins.mixtape.eval_globals` function preloads all estimators
    # from Mixtape, as well as sklearn.pipeline.Pipeline.


search:
    # the search section specifies the space of hyperparameters to search over
    # and the strategy for doing so

    # hyperopt's tree of parzen estimators http://hyperopt.github.io/hyperopt/
    # and random search are curently supported.
    engine: hyperopt_tpe
    engine: random

    space:
        # the search space is specified by listing the variables you want to
        # optimize over and their bounds for float and int typed variables,
        # or the possible choices for enumeration-typed variables.

        featurizer__types:
            choices:
                - ['phi', 'psi']
                - ['phi', 'psi', 'chi1']
            type: enum

        cluster__n_clusters:
            min: 10
            max: 100
            type: int       # from 10 to 100 (with inclusive endpoints)

        tica__gamma:
            min: 1e-10
            max: 1e-1
            type: float
            warp: log       # optimize using the log of the parameter


cv: 5  # the order of K-fold cross validation to use


dataset:
    # specification of the dataset on which to train the models.
    # the __loader__ key idenfities the function that interpets the
    # remaining keys and loads the dataset.

    __loader__: osprey.plugins.mixtape.trajectory_dataset
    trajectories: ~/local/msmbuilder/Tutorial/XTC/*/*.xtc
    topology: ~/local/msmbuilder/Tutorial/native.pdb
    stride: 1


trials:
    # path to a databse in which the results of each hyperparameter fit
    # are stored any SQL database is suppoted, but we recommend using
    # SQLLite, which is simple and stores the results in a file on disk.
    # the string format for connecting to other database is described here:
    # http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html#database-urls

    uri: sqlite:///osprey-trials.db

    # table_name: trials  # (to change the name of the SQL table, if you want)
