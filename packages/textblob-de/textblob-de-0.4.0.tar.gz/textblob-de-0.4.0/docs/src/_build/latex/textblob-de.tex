% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{textblob-de Documentation}
\date{September 17, 2014}
\release{0.4.0}
\author{Markus Killer}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}


Release 0.4.0 ({\hyperref[changelog:changelog]{\emph{Changelog}}})

\href{http://textblob.readthedocs.org/}{TextBlob} is a Python (2 and 3) library for processing textual data.
It is being developed by \href{http://stevenloria.com/}{Steven Loria}. It provides a simple API for diving into
common natural language processing (NLP) tasks such as part-of-speech tagging,
noun phrase extraction, sentiment analysis, classification,
translation, and more.

\textbf{{}`textblob-de{}`} is the \textbf{German language extension} for \href{http://textblob.readthedocs.org/}{TextBlob}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{TextBlobDE}

\PYG{n}{text} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}\PYGZsq{}\PYGZsq{}}
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Der Blob}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ macht in seiner unbekümmert\PYGZhy{}naiven Weise einfach nur Spass.}
\PYG{l+s}{Er hat eben den gewissen Charme, bei dem auch die eher hölzerne Regie und}
\PYG{l+s}{das konfuse Drehbuch nicht weiter stören.}
\PYG{l+s}{\PYGZsq{}\PYGZsq{}\PYGZsq{}}

\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlobDE}\PYG{p}{(}\PYG{n}{text}\PYG{p}{)}
\PYG{n}{blob}\PYG{o}{.}\PYG{n}{tags}           \PYG{c}{\PYGZsh{} [(\PYGZsq{}Der\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}), (\PYGZsq{}Blob\PYGZsq{}, \PYGZsq{}NN\PYGZsq{}), (\PYGZsq{}macht\PYGZsq{}, \PYGZsq{}VB\PYGZsq{}),}
                    \PYG{c}{\PYGZsh{}  (\PYGZsq{}in\PYGZsq{}, \PYGZsq{}IN\PYGZsq{}), (\PYGZsq{}seiner\PYGZsq{}, \PYGZsq{}PRP\PYGZdl{}\PYGZsq{}), ...]}

\PYG{n}{blob}\PYG{o}{.}\PYG{n}{noun\PYGZus{}phrases}   \PYG{c}{\PYGZsh{} WordList([\PYGZsq{}Der Blob\PYGZsq{}, \PYGZsq{}seiner unbekümmert\PYGZhy{}naiven Weise\PYGZsq{},}
                    \PYG{c}{\PYGZsh{}           \PYGZsq{}den gewissen Charme\PYGZsq{}, \PYGZsq{}hölzerne Regie\PYGZsq{},}
                    \PYG{c}{\PYGZsh{}           \PYGZsq{}konfuse Drehbuch\PYGZsq{}])}


\PYG{k}{for} \PYG{n}{sentence} \PYG{o+ow}{in} \PYG{n}{blob}\PYG{o}{.}\PYG{n}{sentences}\PYG{p}{:}
    \PYG{k}{print}\PYG{p}{(}\PYG{n}{sentence}\PYG{o}{.}\PYG{n}{sentiment}\PYG{o}{.}\PYG{n}{polarity}\PYG{p}{)}
\PYG{c}{\PYGZsh{} 1.0}
\PYG{c}{\PYGZsh{} 0.0}

\PYG{n}{blob}\PYG{o}{.}\PYG{n}{translate}\PYG{p}{(}\PYG{n}{to}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{es}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}  \PYG{c}{\PYGZsh{} \PYGZsq{}\PYGZdq{} The Blob \PYGZdq{} hace a su manera ingenua...\PYGZsq{}}
\end{Verbatim}

For a complete overview of \emph{TextBlob} `s features, see documentation of
the main \href{http://textblob.readthedocs.org/}{TextBlob} library.

The docs of the German language extension focus on additions/differences to
\href{http://textblob.readthedocs.org/}{TextBlob} and provide a detailed API reference.


\chapter{Guide}
\label{index:guide}\label{index:textblob-de}

\section{textblob-de README}
\label{readme:textblob-de-readme}\label{readme::doc}\href{https://pypi.python.org/pypi/textblob-de/}{}\href{https://travis-ci.org/markuskiller/textblob-de}{}\href{http://textblob-de.readthedocs.org/en/latest/}{}\href{https://pypi.python.org/pypi/textblob-de/}{}\href{http://choosealicense.com/licenses/mit/}{}
German language support for \href{http://textblob.readthedocs.org/en/dev/}{TextBlob} by Steven Loria.

This python package is being developed as a \code{TextBlob} \textbf{Language Extension}.
See \href{https://textblob.readthedocs.org/en/dev/contributing.html}{Extension Guidelines} for details.


\subsection{Features}
\label{readme:features}\begin{itemize}
\item {} 
All directly accessible \code{textblob\_de} classes (e.g. \code{Sentence()} or \code{Word()}) are initialized with default models for German

\item {} 
Properties or methods that do not yet work for German raise a \code{NotImplementedError}

\item {} 
German sentence boundary detection and tokenization (\code{NLTKPunktTokenizer})

\item {} 
Consistent use of specified tokenizer for all tools (\code{NLTKPunktTokenizer} or \code{PatternTokenizer})

\item {} 
Part-of-speech tagging (\code{PatternTagger}) with keyword \code{include\_punc=True} (defaults to \code{False})

\item {} 
Parsing (\code{PatternParser}) with all \code{pattern} keywords, plus \code{pprint=True} (defaults to \code{False})

\item {} 
Noun Phrase Extraction (\code{PatternParserNPExtractor})

\item {} 
Lemmatization (\code{PatternParserLemmatizer})

\item {} 
Polarity detection (\code{PatternAnalyzer}) - Still \textbf{EXPERIMENTAL}, does not yet have information on subjectivity

\item {} 
Full \code{pattern.text.de} API support on Python3

\item {} 
Supports Python 2 and 3

\item {} 
See \href{http://langui.ch/nlp/python/textblob-de/}{working features overview} for details

\end{itemize}


\subsection{Installing/Upgrading}
\label{readme:installing-upgrading}
\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} pip install \PYGZhy{}U textblob\PYGZhy{}de
\PYGZdl{} python \PYGZhy{}m textblob.download\PYGZus{}corpora
\end{Verbatim}

Or the latest development release (apparently this does not always work on Windows see
\href{https://github.com/pypa/pip/pull/1745}{issues \#1744/5} for details):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} pip install \PYGZhy{}U git+https://github.com/markuskiller/textblob\PYGZhy{}de.git@dev
\PYGZdl{} python \PYGZhy{}m textblob.download\PYGZus{}corpora
\end{Verbatim}

\begin{notice}{note}{Note:}
\code{TextBlob} will be installed/upgraded automatically when running
\code{pip install}. The second line (\code{python -m textblob.download\_corpora})
downloads/updates nltk corpora and language models used in \code{TextBlob}.
\end{notice}


\subsection{Usage}
\label{readme:usage}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{TextBlobDE} \PYG{k}{as} \PYG{n}{TextBlob}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{text} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}\PYGZsq{}\PYGZsq{}}\PYG{l+s}{Heute ist der 3. Mai 2014 und Dr. Meier feiert seinen 43. Geburtstag.}
\PYG{g+go}{Ich muss unbedingt daran denken, Mehl, usw. für einen Kuchen einzukaufen. Aber leider}
\PYG{g+go}{habe ich nur noch EUR 3.50 in meiner Brieftasche.\PYGZsq{}\PYGZsq{}\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{n}{text}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{sentences}
\PYG{g+go}{[Sentence(\PYGZdq{}Heute ist der 3. Mai 2014 und Dr. Meier feiert seinen 43. Geburtstag.\PYGZdq{}),}
\PYG{g+go}{ Sentence(\PYGZdq{}Ich muss unbedingt daran denken, Mehl, usw. für einen Kuchen einzukaufen.\PYGZdq{}),}
\PYG{g+go}{ Sentence(\PYGZdq{}Aber leider habe ich nur noch EUR 3.50 in meiner Brieftasche.\PYGZdq{})]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{tokens}
\PYG{g+go}{WordList([\PYGZsq{}Heute\PYGZsq{}, \PYGZsq{}ist\PYGZsq{}, \PYGZsq{}der\PYGZsq{}, \PYGZsq{}3.\PYGZsq{}, \PYGZsq{}Mai\PYGZsq{}, ...]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{tags}
\PYG{g+go}{[(\PYGZsq{}Heute\PYGZsq{}, \PYGZsq{}RB\PYGZsq{}), (\PYGZsq{}ist\PYGZsq{}, \PYGZsq{}VB\PYGZsq{}), (\PYGZsq{}der\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}), (\PYGZsq{}3.\PYGZsq{}, \PYGZsq{}LS\PYGZsq{}), (\PYGZsq{}Mai\PYGZsq{}, \PYGZsq{}NN\PYGZsq{}),}
\PYG{g+go}{(\PYGZsq{}2014\PYGZsq{}, \PYGZsq{}CD\PYGZsq{}), ...]}
\PYG{g+go}{\PYGZsh{} Default: Only noun\PYGZus{}phrases that consist of two or more meaningful parts are displayed.}
\PYG{g+go}{\PYGZsh{} Not perfect, but a start (relies heavily on parser accuracy)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{noun\PYGZus{}phrases}
\PYG{g+go}{WordList([\PYGZsq{}Mai 2014\PYGZsq{}, \PYGZsq{}Dr. Meier\PYGZsq{}, \PYGZsq{}seinen 43. Geburtstag\PYGZsq{}, \PYGZsq{}Kuchen einzukaufen\PYGZsq{},}
\PYG{g+go}{\PYGZsq{}meiner Brieftasche\PYGZsq{}])}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das Auto ist sehr schön.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{\PYGZsq{}Das/DT/B\PYGZhy{}NP/O Auto/NN/I\PYGZhy{}NP/O ist/VB/B\PYGZhy{}VP/O sehr/RB/B\PYGZhy{}ADJP/O schön/JJ/I\PYGZhy{}ADJP/O\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{PatternParser}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlobDE}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das ist ein schönes Auto.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{parser}\PYG{o}{=}\PYG{n}{PatternParser}\PYG{p}{(}\PYG{n}{pprint}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{lemmata}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{parse}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{      WORD   TAG    CHUNK   ROLE   ID     PNP    LEMMA}

\PYG{g+go}{       Das   DT     \PYGZhy{}       \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      das}
\PYG{g+go}{       ist   VB     VP      \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      sein}
\PYG{g+go}{       ein   DT     NP      \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      ein}
\PYG{g+go}{   schönes   JJ     NP \PYGZca{}    \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      schön}
\PYG{g+go}{      Auto   NN     NP \PYGZca{}    \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      auto}
\PYG{g+go}{         .   .      \PYGZhy{}       \PYGZhy{}      \PYGZhy{}      \PYGZhy{}      .}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{PatternTagger}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{n}{text}\PYG{p}{,} \PYG{n}{pos\PYGZus{}tagger}\PYG{o}{=}\PYG{n}{PatternTagger}\PYG{p}{(}\PYG{n}{include\PYGZus{}punc}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{[(\PYGZsq{}Das\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}), (\PYGZsq{}Auto\PYGZsq{}, \PYGZsq{}NN\PYGZsq{}), (\PYGZsq{}ist\PYGZsq{}, \PYGZsq{}VB\PYGZsq{}), (\PYGZsq{}sehr\PYGZsq{}, \PYGZsq{}RB\PYGZsq{}), (\PYGZsq{}schön\PYGZsq{}, \PYGZsq{}JJ\PYGZsq{}), (\PYGZsq{}.\PYGZsq{}, \PYGZsq{}.\PYGZsq{})]}
\end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das Auto ist sehr schön.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{sentiment}
\PYG{g+go}{Sentiment(polarity=1.0, subjectivity=0.0)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das ist ein hässliches Auto.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{sentiment}
\PYG{g+go}{Sentiment(polarity=\PYGZhy{}1.0, subjectivity=0.0)}
\end{Verbatim}

\begin{notice}{warning}{Warning:}
\textbf{WORK IN PROGRESS:} The German polarity lexicon contains only uninflected
forms and there are no subjectivity scores yet. As of version 0.2.3, lemmatized
word forms are submitted to the \code{PatternAnalyzer}, increasing the accuracy
of polarity values. New in version 0.2.7: return type of \code{.sentiment} is now
adapted to the main \href{http://textblob.readthedocs.org/en/dev/}{TextBlob} library (\code{:rtype: namedtuple}).
\end{notice}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob}\PYG{o}{.}\PYG{n}{words}\PYG{o}{.}\PYG{n}{lemmatize}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{WordList([\PYGZsq{}das\PYGZsq{}, \PYGZsq{}sein\PYGZsq{}, \PYGZsq{}ein\PYGZsq{}, \PYGZsq{}hässlich\PYGZsq{}, \PYGZsq{}Auto\PYGZsq{}])}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.lemmatizers} \PYG{k+kn}{import} \PYG{n}{PatternParserLemmatizer}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{\PYGZus{}lemmatizer} \PYG{o}{=} \PYG{n}{PatternParserLemmatizer}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{\PYGZus{}lemmatizer}\PYG{o}{.}\PYG{n}{lemmatize}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das ist ein hässliches Auto.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{[(\PYGZsq{}das\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}), (\PYGZsq{}sein\PYGZsq{}, \PYGZsq{}VB\PYGZsq{}), (\PYGZsq{}ein\PYGZsq{}, \PYGZsq{}DT\PYGZsq{}), (\PYGZsq{}hässlich\PYGZsq{}, \PYGZsq{}JJ\PYGZsq{}), (\PYGZsq{}Auto\PYGZsq{}, \PYGZsq{}NN\PYGZsq{})]}
\end{Verbatim}

\begin{notice}{note}{Note:}
Make sure that you use unicode strings on Python2 if your input contains
non-ascii characters (e.g. \code{word = u"schön"}).
\end{notice}


\subsection{Access to \texttt{pattern} API in Python3}
\label{readme:access-to-pattern-api-in-python3}
\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.packages} \PYG{k+kn}{import} \PYG{n}{pattern\PYGZus{}de} \PYG{k}{as} \PYG{n}{pd}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{print}\PYG{p}{(}\PYG{n}{pd}\PYG{o}{.}\PYG{n}{attributive}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{neugierig}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{gender}\PYG{o}{=}\PYG{n}{pd}\PYG{o}{.}\PYG{n}{FEMALE}\PYG{p}{,} \PYG{n}{role}\PYG{o}{=}\PYG{n}{pd}\PYG{o}{.}\PYG{n}{INDIRECT}\PYG{p}{,} \PYG{n}{article}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{die}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{g+go}{neugierigen}
\end{Verbatim}

\begin{notice}{note}{Note:}
Alternatively, the path to \code{textblob\_de/ext} can be added to the \code{PYTHONPATH}, which allows
the use of \code{pattern.de} in almost the same way as described in its
\href{http://www.clips.ua.ac.be/pages/pattern-de}{Documentation}.
The only difference is that you will have to prepend an underscore:
\code{from \_pattern.de import ...}. This is a precautionary measure in case the \code{pattern}
library gets native Python3 support in the future.
\end{notice}


\subsection{Documentation and API Reference}
\label{readme:documentation-and-api-reference}\begin{itemize}
\item {} 
\href{http://textblob-de.readthedocs.org/en/latest}{http://textblob-de.readthedocs.org/en/latest}

\end{itemize}


\subsection{Requirements}
\label{readme:requirements}\begin{itemize}
\item {} 
Python \textgreater{}= 2.6 or \textgreater{}= 3.3

\end{itemize}


\subsection{TODO}
\label{readme:todo}\begin{itemize}
\item {} 
\href{http://textblob-de.readthedocs.org/en/latest/extensions.html}{Planned Extensions}

\item {} 
Additional PoS tagging options, e.g. NLTK tagging (\code{NLTKTagger})

\item {} 
Improve noun phrase extraction (e.g. based on \code{RFTagger} output)

\item {} 
Improve sentiment analysis (find suitable subjectivity scores)

\item {} 
Improve functionality of \code{Sentence()} and \code{Word()} objects

\item {} 
Adapt more tests from the main \href{http://textblob.readthedocs.org/en/dev/}{TextBlob} library (esp. for \code{TextBlobDE()} in \code{test\_blob.py})

\end{itemize}


\subsection{License}
\label{readme:license}
\href{http://choosealicense.com/licenses/mit/}{MIT licensed}. See the bundled \code{LICENSE}  file for more details.


\subsection{Thanks}
\label{readme:thanks}
Coded with Wing IDE 5.0 (free open source developer license)
\href{https://wingware.com/store/free}{}

\section{Tutorial: Quickstart}
\label{quickstart:tutorial-quickstart}\label{quickstart::doc}\label{quickstart:quickstart}
Use the following line as your first import ...

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{TextBlobDE} \PYG{k}{as} \PYG{n}{TextBlob}
\end{Verbatim}

... and follow the \href{http://textblob.readthedocs.org/en/dev/quickstart.html}{quickstart guide}
in the documentation of the main package (using German examples and starting with
``Let's create our first \textbf{TextBlob}'').


\section{Advanced Usage: Overriding Models and the Blobber Class}
\label{advanced_usage::doc}\label{advanced_usage:advanced}\label{advanced_usage:advanced-usage-overriding-models-and-the-blobber-class}
Follow the \href{http://textblob.readthedocs.org/en/dev/advanced\_usage.html}{Advanced Usage guide}
in the documentation of the main package (using German examples). The following
minimal replacements are necessary in order to enable the use of the German default models:

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textsf{\relax 
\textbf{Instead of:}
} & \textsf{\relax 
\textbf{Use:}
}\\
\hline
\code{textblob}
 & 
\code{textblob\_de}
\\

\code{TextBlob}
 & 
\code{TextBlobDE}
\\

\code{Blobber}
 & 
\code{BlobberDE}
\\
\hline\end{tabulary}



\section{Extensions}
\label{extensions:extensions}\label{extensions::doc}

\begin{threeparttable}
\capstart\caption{Planned extensions}

\begin{tabulary}{\linewidth}{|L|L|L|}
\hline
\textsf{\relax 
Extension
} & \textsf{\relax 
Purpose
} & \textsf{\relax 
Status (in private repo)
}\\
\hline
\code{textblob-rftagger}
 & 
wrapper class for \code{RFTagger}
 & 
95\% completed
\\

\code{textblob-cmd}
 & 
command-line wrapper for \code{TextBlob}
 & 
50\% completed
\\

\code{textblob-stanfordparser}
 & 
wrapper class for \code{StanfordParser}
 & 
25\% completed
\\

\code{textblob-berkeleyparser}
 & 
wrapper class for \code{BerkeleyParser}
 & 
0\% completed
\\

\code{textblob-sent-align}
 & 
sentence alignment for parallel TextBlobs
 & 
40\% completed
\\

\code{textblob-converters}
 & 
various input and output conversions
 & 
20\% completed
\\
\hline\end{tabulary}

\end{threeparttable}


See also notes on \href{http://textblob.readthedocs.org/en/dev/extensions.html}{Extensions}
in the documentation of the main package.


\section{API Reference}
\label{api_reference:api-reference}\label{api_reference:api}\label{api_reference::doc}

\subsection{Blob Classes}
\label{api_reference:blob-classes}\label{api_reference:module-textblob_de.blob}\index{textblob\_de.blob (module)}
Wrappers for various units of text.

This includes the main {\hyperref[api_reference:textblob_de.blob.TextBlobDE]{\code{TextBlobDE}}},
{\hyperref[api_reference:textblob_de.blob.Word]{\code{Word}}}, and {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}} classes.

Whenever possible, classes are inherited from the main \href{http://textblob.readthedocs.org/}{TextBlob} library, but in many
cases, the models for German have to be initialised here in {\hyperref[api_reference:module-textblob_de.blob]{\code{textblob\_de.blob}}}, resulting 
in a lot of duplicate code. The main reason being the {\hyperref[api_reference:textblob_de.blob.Word]{\code{Word}}} objects. 
If they are generated from an inherited class, they will use the English models 
(e.g. for \code{pluralize}/\code{singularize}) used in the main library.

Example usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{TextBlobDE}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b} \PYG{o}{=} \PYG{n}{TextBlobDE}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Einfach ist besser als kompliziert.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{tags}
\PYG{g+go}{[(\PYGZsq{}Einfach\PYGZsq{}, \PYGZsq{}RB\PYGZsq{}), (\PYGZsq{}ist\PYGZsq{}, \PYGZsq{}VB\PYGZsq{}), (\PYGZsq{}besser\PYGZsq{}, \PYGZsq{}RB\PYGZsq{}), (\PYGZsq{}als\PYGZsq{}, \PYGZsq{}IN\PYGZsq{}), (\PYGZsq{}kompliziert\PYGZsq{}, \PYGZsq{}JJ\PYGZsq{})]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{noun\PYGZus{}phrases}
\PYG{g+go}{WordList([])}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{words}
\PYG{g+go}{WordList([\PYGZsq{}Einfach\PYGZsq{}, \PYGZsq{}ist\PYGZsq{}, \PYGZsq{}besser\PYGZsq{}, \PYGZsq{}als\PYGZsq{}, \PYGZsq{}kompliziert\PYGZsq{}])}
\end{Verbatim}
\index{BaseBlob (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{BaseBlob}}{\emph{text}, \emph{tokenizer=None}, \emph{pos\_tagger=None}, \emph{np\_extractor=None}, \emph{analyzer=None}, \emph{parser=None}, \emph{classifier=None}, \emph{clean\_html=False}}{}
\code{BaseBlob} class initialised with German default models:

An abstract base class that all textblob classes will inherit from.
Includes words, POS tag, NP, and word count properties. Also includes
basic dunder and string methods for making objects like Python strings.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} (\emph{str}) -- A string.

\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\item {} 
\textbf{np\_extractor} -- (optional) An NPExtractor instance. If \code{None},
defaults to {\hyperref[api_reference:textblob_de.np_extractors.PatternParserNPExtractor]{\code{PatternParserNPExtractor()}}}.

\item {} 
\textbf{pos\_tagger} -- (optional) A Tagger instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.taggers.PatternTagger]{\code{PatternTagger}}}.

\item {} 
\textbf{analyzer} -- (optional) A sentiment analyzer. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.sentiments.PatternAnalyzer]{\code{PatternAnalyzer}}}.

\item {} 
\textbf{classifier} -- (optional) A classifier.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{Changed in version 0.6.0: }\code{clean\_html} parameter deprecated, as it was in NLTK.
\index{classify() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.classify}\pysiglinewithargsret{\bfcode{classify}}{}{}
Classify the blob using the blob's \code{classifier}.

\end{fulllineitems}

\index{correct() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.correct}\pysiglinewithargsret{\bfcode{correct}}{}{}
Attempt to correct the spelling of a blob.

\DUspan{versionmodified}{New in version 0.6.0: }(\code{textblob})
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.BaseBlob]{\code{BaseBlob}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{detect\_language() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.detect_language}\pysiglinewithargsret{\bfcode{detect\_language}}{}{}
Detect the blob's language using the Google Translate API.

Requires an internet connection.

Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bonjour}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{detect\PYGZus{}language}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{u\PYGZsq{}fr\PYGZsq{}}
\end{Verbatim}
\begin{description}
\item[{Language code reference:}] \leavevmode
\href{https://developers.google.com/translate/v2/using\_rest\#language-params}{https://developers.google.com/translate/v2/using\_rest\#language-params}

\end{description}

\DUspan{versionmodified}{New in version 0.5.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{ends\_with() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.ends_with}\pysiglinewithargsret{\bfcode{ends\_with}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{endswith() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.endswith}\pysiglinewithargsret{\bfcode{endswith}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{find() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.find}\pysiglinewithargsret{\bfcode{find}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.find() method. Returns an integer,
the index of the first occurrence of the substring argument sub in the
sub-string given by {[}start:end{]}.

\end{fulllineitems}

\index{format() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.format}\pysiglinewithargsret{\bfcode{format}}{\emph{*args}, \emph{**kwargs}}{}
Perform a string formatting operation, like the built-in
\emph{str.format(*args, **kwargs)}. Returns a blob object.

\end{fulllineitems}

\index{index() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.index}\pysiglinewithargsret{\bfcode{index}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.find() but raise ValueError when the substring
is not found.

\end{fulllineitems}

\index{join() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.join}\pysiglinewithargsret{\bfcode{join}}{\emph{iterable}}{}
Behaves like the built-in \emph{str.join(iterable)} method, except
returns a blob object.

Returns a blob which is the concatenation of the strings or blobs
in the iterable.

\end{fulllineitems}

\index{lower() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.lower}\pysiglinewithargsret{\bfcode{lower}}{}{}
Like str.lower(), returns new object with all lower-cased characters.

\end{fulllineitems}

\index{ngrams() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.ngrams}\pysiglinewithargsret{\bfcode{ngrams}}{\emph{n=3}}{}
Return a list of n-grams (tuples of n successive words) for this
blob.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
List of {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordLists}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{noun\_phrases (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.noun_phrases}\pysigline{\bfcode{noun\_phrases}}
Returns a list of noun phrases for this blob.

\end{fulllineitems}

\index{np\_counts (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.np_counts}\pysigline{\bfcode{np\_counts}}
Dictionary of noun phrase frequencies in this text.

\end{fulllineitems}

\index{parse() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.parse}\pysiglinewithargsret{\bfcode{parse}}{\emph{parser=None}}{}
Parse the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{parser} -- (optional) A parser instance. If \code{None}, defaults to
this blob's default parser.

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.0.}

\end{fulllineitems}

\index{polarity (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.polarity}\pysigline{\bfcode{polarity}}
Return the polarity score as a float within the range {[}-1.0, 1.0{]}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{pos\_tags (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.pos_tags}\pysigline{\bfcode{pos\_tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{replace() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.replace}\pysiglinewithargsret{\bfcode{replace}}{\emph{old}, \emph{new}, \emph{count=9223372036854775807}}{}
Return a new blob object with all the occurence of \emph{old} replaced
by \emph{new}.

\end{fulllineitems}

\index{rfind() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.rfind}\pysiglinewithargsret{\bfcode{rfind}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.rfind() method. Returns an integer,
the index of he last (right-most) occurence of the substring argument
sub in the sub-sequence given by {[}start:end{]}.

\end{fulllineitems}

\index{rindex() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.rindex}\pysiglinewithargsret{\bfcode{rindex}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.rfind() but raise ValueError when substring is not
found.

\end{fulllineitems}

\index{sentiment (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.sentiment}\pysigline{\bfcode{sentiment}}
Return a tuple of form (polarity, subjectivity ) where polarity
is a float within the range {[}-1.0, 1.0{]} and subjectivity is a float
within the range {[}0.0, 1.0{]} where 0.0 is very objective and 1.0 is
very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
namedtuple of the form \code{Sentiment(polarity, subjectivity)}

\end{description}\end{quote}

\end{fulllineitems}

\index{split() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.split}\pysiglinewithargsret{\bfcode{split}}{\emph{sep=None}, \emph{maxsplit=9223372036854775807}}{}
Behaves like the built-in str.split() except returns a
WordList.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{starts\_with() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.starts_with}\pysiglinewithargsret{\bfcode{starts\_with}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{startswith() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.startswith}\pysiglinewithargsret{\bfcode{startswith}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{strip() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.strip}\pysiglinewithargsret{\bfcode{strip}}{\emph{chars=None}}{}
Behaves like the built-in str.strip({[}chars{]}) method. Returns
an object with leading and trailing whitespace removed.

\end{fulllineitems}

\index{subjectivity (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.subjectivity}\pysigline{\bfcode{subjectivity}}
Return the subjectivity score as a float within the range {[}0.0, 1.0{]}
where 0.0 is very objective and 1.0 is very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{tags (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.tags}\pysigline{\bfcode{tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{title() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.title}\pysiglinewithargsret{\bfcode{title}}{}{}
Returns a blob object with the text in title-case.

\end{fulllineitems}

\index{tokenize() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{tokenizer=None}}{}
Return a list of tokens, using \code{tokenizer}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer object. If None, defaults to
this blob's default tokenizer.

\end{description}\end{quote}

\end{fulllineitems}

\index{tokens (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.tokens}\pysigline{\bfcode{tokens}}
Return a list of tokens, using this blob's tokenizer object
(defaults to \code{WordTokenizer}).

\end{fulllineitems}

\index{translate() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.translate}\pysiglinewithargsret{\bfcode{translate}}{\emph{from\_lang=None}, \emph{to='de'}}{}
Translate the blob to another language.

\end{fulllineitems}

\index{upper() (textblob\_de.blob.BaseBlob method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.upper}\pysiglinewithargsret{\bfcode{upper}}{}{}
Like str.upper(), returns new object with all upper-cased characters.

\end{fulllineitems}

\index{word\_counts (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.word_counts}\pysigline{\bfcode{word\_counts}}
Dictionary of word frequencies in this text.

\end{fulllineitems}

\index{words (textblob\_de.blob.BaseBlob attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BaseBlob.words}\pysigline{\bfcode{words}}
Return a list of word tokens. This excludes punctuation characters.
If you want to include punctuation characters, access the \code{tokens}
property.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}} of word tokens.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{BlobberDE (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BlobberDE}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{BlobberDE}}{\emph{tokenizer=None}, \emph{pos\_tagger=None}, \emph{np\_extractor=None}, \emph{analyzer=None}, \emph{parser=None}, \emph{classifier=None}}{}
A factory for TextBlobs that all share the same tagger, tokenizer,
parser, classifier, and np\_extractor.

Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{BlobberDE}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.taggers} \PYG{k+kn}{import} \PYG{n}{PatternTagger}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob.tokenizers} \PYG{k+kn}{import} \PYG{n}{PatternTokenizer}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{tb} \PYG{o}{=} \PYG{n}{Blobber}\PYG{p}{(}\PYG{n}{pos\PYGZus{}tagger}\PYG{o}{=}\PYG{n}{PatternTagger}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{o}{=}\PYG{n}{PatternTokenizer}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob1} \PYG{o}{=} \PYG{n}{tb}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das ist ein Blob.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob2} \PYG{o}{=} \PYG{n}{tb}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dieser Blob benutzt die selben Tagger und Tokenizer.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob1}\PYG{o}{.}\PYG{n}{pos\PYGZus{}tagger} \PYG{o+ow}{is} \PYG{n}{blob2}\PYG{o}{.}\PYG{n}{pos\PYGZus{}tagger}
\PYG{g+go}{True}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} (\emph{str}) -- A string.

\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\item {} 
\textbf{np\_extractor} -- (optional) An NPExtractor instance. If \code{None},
defaults to {\hyperref[api_reference:textblob_de.np_extractors.PatternParserNPExtractor]{\code{PatternParserNPExtractor()}}}.

\item {} 
\textbf{pos\_tagger} -- (optional) A Tagger instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.taggers.PatternTagger]{\code{PatternTagger}}}.

\item {} 
\textbf{analyzer} -- (optional) A sentiment analyzer. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.sentiments.PatternAnalyzer]{\code{PatternAnalyzer}}}.

\item {} 
\textbf{classifier} -- (optional) A classifier.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.4.0: }(\code{textblob})

\end{fulllineitems}

\index{Sentence (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{Sentence}}{\emph{sentence}, \emph{start\_index=0}, \emph{end\_index=None}, \emph{*args}, \emph{**kwargs}}{}
A sentence within a TextBlob. Inherits from {\hyperref[api_reference:textblob_de.blob.BaseBlob]{\code{BaseBlob}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{sentence} -- A string, the raw sentence.

\item {} 
\textbf{start\_index} -- An int, the index where this sentence begins
in a TextBlob. If not given, defaults to 0.

\item {} 
\textbf{end\_index} -- An int, the index where this sentence ends in
a TextBlob. If not given, defaults to the
length of the sentence - 1.

\end{itemize}

\end{description}\end{quote}
\index{classify() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.classify}\pysiglinewithargsret{\bfcode{classify}}{}{}
Classify the blob using the blob's \code{classifier}.

\end{fulllineitems}

\index{correct() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.correct}\pysiglinewithargsret{\bfcode{correct}}{}{}
Attempt to correct the spelling of a blob.

\DUspan{versionmodified}{New in version 0.6.0: }(\code{textblob})
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.BaseBlob]{\code{BaseBlob}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{detect\_language() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.detect_language}\pysiglinewithargsret{\bfcode{detect\_language}}{}{}
Detect the blob's language using the Google Translate API.

Requires an internet connection.

Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bonjour}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{detect\PYGZus{}language}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{u\PYGZsq{}fr\PYGZsq{}}
\end{Verbatim}
\begin{description}
\item[{Language code reference:}] \leavevmode
\href{https://developers.google.com/translate/v2/using\_rest\#language-params}{https://developers.google.com/translate/v2/using\_rest\#language-params}

\end{description}

\DUspan{versionmodified}{New in version 0.5.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{dict (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.dict}\pysigline{\bfcode{dict}}
The dict representation of this sentence.

\end{fulllineitems}

\index{end (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.end}\pysigline{\bfcode{end}\strong{ = None}}
The end index within a textBlob

\end{fulllineitems}

\index{end\_index (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.end_index}\pysigline{\bfcode{end\_index}\strong{ = None}}
The end index within a textBlob

\end{fulllineitems}

\index{ends\_with() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.ends_with}\pysiglinewithargsret{\bfcode{ends\_with}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{endswith() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.endswith}\pysiglinewithargsret{\bfcode{endswith}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{find() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.find}\pysiglinewithargsret{\bfcode{find}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.find() method. Returns an integer,
the index of the first occurrence of the substring argument sub in the
sub-string given by {[}start:end{]}.

\end{fulllineitems}

\index{format() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.format}\pysiglinewithargsret{\bfcode{format}}{\emph{*args}, \emph{**kwargs}}{}
Perform a string formatting operation, like the built-in
\emph{str.format(*args, **kwargs)}. Returns a blob object.

\end{fulllineitems}

\index{index() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.index}\pysiglinewithargsret{\bfcode{index}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.find() but raise ValueError when the substring
is not found.

\end{fulllineitems}

\index{join() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.join}\pysiglinewithargsret{\bfcode{join}}{\emph{iterable}}{}
Behaves like the built-in \emph{str.join(iterable)} method, except
returns a blob object.

Returns a blob which is the concatenation of the strings or blobs
in the iterable.

\end{fulllineitems}

\index{lower() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.lower}\pysiglinewithargsret{\bfcode{lower}}{}{}
Like str.lower(), returns new object with all lower-cased characters.

\end{fulllineitems}

\index{ngrams() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.ngrams}\pysiglinewithargsret{\bfcode{ngrams}}{\emph{n=3}}{}
Return a list of n-grams (tuples of n successive words) for this
blob.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
List of {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordLists}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{noun\_phrases (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.noun_phrases}\pysigline{\bfcode{noun\_phrases}}
Returns a list of noun phrases for this blob.

\end{fulllineitems}

\index{np\_counts (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.np_counts}\pysigline{\bfcode{np\_counts}}
Dictionary of noun phrase frequencies in this text.

\end{fulllineitems}

\index{parse() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.parse}\pysiglinewithargsret{\bfcode{parse}}{\emph{parser=None}}{}
Parse the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{parser} -- (optional) A parser instance. If \code{None}, defaults to
this blob's default parser.

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.0.}

\end{fulllineitems}

\index{polarity (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.polarity}\pysigline{\bfcode{polarity}}
Return the polarity score as a float within the range {[}-1.0, 1.0{]}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{pos\_tags (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.pos_tags}\pysigline{\bfcode{pos\_tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{replace() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.replace}\pysiglinewithargsret{\bfcode{replace}}{\emph{old}, \emph{new}, \emph{count=9223372036854775807}}{}
Return a new blob object with all the occurence of \emph{old} replaced
by \emph{new}.

\end{fulllineitems}

\index{rfind() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.rfind}\pysiglinewithargsret{\bfcode{rfind}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.rfind() method. Returns an integer,
the index of he last (right-most) occurence of the substring argument
sub in the sub-sequence given by {[}start:end{]}.

\end{fulllineitems}

\index{rindex() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.rindex}\pysiglinewithargsret{\bfcode{rindex}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.rfind() but raise ValueError when substring is not
found.

\end{fulllineitems}

\index{sentiment (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.sentiment}\pysigline{\bfcode{sentiment}}
Return a tuple of form (polarity, subjectivity ) where polarity
is a float within the range {[}-1.0, 1.0{]} and subjectivity is a float
within the range {[}0.0, 1.0{]} where 0.0 is very objective and 1.0 is
very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
namedtuple of the form \code{Sentiment(polarity, subjectivity)}

\end{description}\end{quote}

\end{fulllineitems}

\index{split() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.split}\pysiglinewithargsret{\bfcode{split}}{\emph{sep=None}, \emph{maxsplit=9223372036854775807}}{}
Behaves like the built-in str.split() except returns a
WordList.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{start (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.start}\pysigline{\bfcode{start}\strong{ = None}}
The start index within a TextBlob

\end{fulllineitems}

\index{start\_index (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.start_index}\pysigline{\bfcode{start\_index}\strong{ = None}}
The start index within a TextBlob

\end{fulllineitems}

\index{starts\_with() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.starts_with}\pysiglinewithargsret{\bfcode{starts\_with}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{startswith() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.startswith}\pysiglinewithargsret{\bfcode{startswith}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{strip() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.strip}\pysiglinewithargsret{\bfcode{strip}}{\emph{chars=None}}{}
Behaves like the built-in str.strip({[}chars{]}) method. Returns
an object with leading and trailing whitespace removed.

\end{fulllineitems}

\index{subjectivity (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.subjectivity}\pysigline{\bfcode{subjectivity}}
Return the subjectivity score as a float within the range {[}0.0, 1.0{]}
where 0.0 is very objective and 1.0 is very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{tags (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.tags}\pysigline{\bfcode{tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{title() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.title}\pysiglinewithargsret{\bfcode{title}}{}{}
Returns a blob object with the text in title-case.

\end{fulllineitems}

\index{tokenize() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{tokenizer=None}}{}
Return a list of tokens, using \code{tokenizer}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer object. If None, defaults to
this blob's default tokenizer.

\end{description}\end{quote}

\end{fulllineitems}

\index{tokens (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.tokens}\pysigline{\bfcode{tokens}}
Return a list of tokens, using this blob's tokenizer object
(defaults to \code{WordTokenizer}).

\end{fulllineitems}

\index{translate() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.translate}\pysiglinewithargsret{\bfcode{translate}}{\emph{from\_lang=None}, \emph{to='de'}}{}
Translate the blob to another language.

\end{fulllineitems}

\index{upper() (textblob\_de.blob.Sentence method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.upper}\pysiglinewithargsret{\bfcode{upper}}{}{}
Like str.upper(), returns new object with all upper-cased characters.

\end{fulllineitems}

\index{word\_counts (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.word_counts}\pysigline{\bfcode{word\_counts}}
Dictionary of word frequencies in this text.

\end{fulllineitems}

\index{words (textblob\_de.blob.Sentence attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Sentence.words}\pysigline{\bfcode{words}}
Return a list of word tokens. This excludes punctuation characters.
If you want to include punctuation characters, access the \code{tokens}
property.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}} of word tokens.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{TextBlobDE (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{TextBlobDE}}{\emph{text}, \emph{tokenizer=None}, \emph{pos\_tagger=None}, \emph{np\_extractor=None}, \emph{analyzer=None}, \emph{parser=None}, \emph{classifier=None}, \emph{clean\_html=False}}{}
\code{TextBlob} class initialised with German default models:
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} (\emph{str}) -- A string.

\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\item {} 
\textbf{np\_extractor} -- (optional) An NPExtractor instance. If \code{None},
defaults to {\hyperref[api_reference:textblob_de.np_extractors.PatternParserNPExtractor]{\code{PatternParserNPExtractor()}}}.

\item {} 
\textbf{pos\_tagger} -- (optional) A Tagger instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.taggers.PatternTagger]{\code{PatternTagger}}}.

\item {} 
\textbf{analyzer} -- (optional) A sentiment analyzer. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.sentiments.PatternAnalyzer]{\code{PatternAnalyzer}}}.

\item {} 
\textbf{classifier} -- (optional) A classifier.

\end{itemize}

\end{description}\end{quote}
\index{classify() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.classify}\pysiglinewithargsret{\bfcode{classify}}{}{}
Classify the blob using the blob's \code{classifier}.

\end{fulllineitems}

\index{correct() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.correct}\pysiglinewithargsret{\bfcode{correct}}{}{}
Attempt to correct the spelling of a blob.

\DUspan{versionmodified}{New in version 0.6.0: }(\code{textblob})
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.BaseBlob]{\code{BaseBlob}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{detect\_language() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.detect_language}\pysiglinewithargsret{\bfcode{detect\_language}}{}{}
Detect the blob's language using the Google Translate API.

Requires an internet connection.

Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bonjour}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{b}\PYG{o}{.}\PYG{n}{detect\PYGZus{}language}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{u\PYGZsq{}fr\PYGZsq{}}
\end{Verbatim}
\begin{description}
\item[{Language code reference:}] \leavevmode
\href{https://developers.google.com/translate/v2/using\_rest\#language-params}{https://developers.google.com/translate/v2/using\_rest\#language-params}

\end{description}

\DUspan{versionmodified}{New in version 0.5.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{ends\_with() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.ends_with}\pysiglinewithargsret{\bfcode{ends\_with}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{endswith() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.endswith}\pysiglinewithargsret{\bfcode{endswith}}{\emph{suffix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob ends with the given suffix.

\end{fulllineitems}

\index{find() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.find}\pysiglinewithargsret{\bfcode{find}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.find() method. Returns an integer,
the index of the first occurrence of the substring argument sub in the
sub-string given by {[}start:end{]}.

\end{fulllineitems}

\index{format() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.format}\pysiglinewithargsret{\bfcode{format}}{\emph{*args}, \emph{**kwargs}}{}
Perform a string formatting operation, like the built-in
\emph{str.format(*args, **kwargs)}. Returns a blob object.

\end{fulllineitems}

\index{index() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.index}\pysiglinewithargsret{\bfcode{index}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.find() but raise ValueError when the substring
is not found.

\end{fulllineitems}

\index{join() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.join}\pysiglinewithargsret{\bfcode{join}}{\emph{iterable}}{}
Behaves like the built-in \emph{str.join(iterable)} method, except
returns a blob object.

Returns a blob which is the concatenation of the strings or blobs
in the iterable.

\end{fulllineitems}

\index{json (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.json}\pysigline{\bfcode{json}}
The json representation of this blob.

\DUspan{versionmodified}{Changed in version 0.5.1: }Made \code{json} a property instead of a method to restore backwards
compatibility that was broken after version 0.4.0.

\end{fulllineitems}

\index{lower() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.lower}\pysiglinewithargsret{\bfcode{lower}}{}{}
Like str.lower(), returns new object with all lower-cased characters.

\end{fulllineitems}

\index{ngrams() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.ngrams}\pysiglinewithargsret{\bfcode{ngrams}}{\emph{n=3}}{}
Return a list of n-grams (tuples of n successive words) for this
blob.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
List of {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordLists}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{noun\_phrases (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.noun_phrases}\pysigline{\bfcode{noun\_phrases}}
Returns a list of noun phrases for this blob.

\end{fulllineitems}

\index{np\_counts (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.np_counts}\pysigline{\bfcode{np\_counts}}
Dictionary of noun phrase frequencies in this text.

\end{fulllineitems}

\index{parse() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.parse}\pysiglinewithargsret{\bfcode{parse}}{\emph{parser=None}}{}
Parse the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{parser} -- (optional) A parser instance. If \code{None}, defaults to
this blob's default parser.

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.0.}

\end{fulllineitems}

\index{polarity (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.polarity}\pysigline{\bfcode{polarity}}
Return the polarity score as a float within the range {[}-1.0, 1.0{]}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{pos\_tags (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.pos_tags}\pysigline{\bfcode{pos\_tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{raw\_sentences (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.raw_sentences}\pysigline{\bfcode{raw\_sentences}}
List of strings, the raw sentences in the blob.

\end{fulllineitems}

\index{replace() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.replace}\pysiglinewithargsret{\bfcode{replace}}{\emph{old}, \emph{new}, \emph{count=9223372036854775807}}{}
Return a new blob object with all the occurence of \emph{old} replaced
by \emph{new}.

\end{fulllineitems}

\index{rfind() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.rfind}\pysiglinewithargsret{\bfcode{rfind}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Behaves like the built-in str.rfind() method. Returns an integer,
the index of he last (right-most) occurence of the substring argument
sub in the sub-sequence given by {[}start:end{]}.

\end{fulllineitems}

\index{rindex() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.rindex}\pysiglinewithargsret{\bfcode{rindex}}{\emph{sub}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Like blob.rfind() but raise ValueError when substring is not
found.

\end{fulllineitems}

\index{sentences (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.sentences}\pysigline{\bfcode{sentences}}
Return list of {\hyperref[api_reference:textblob_de.blob.Sentence]{\code{Sentence}}} objects.

\end{fulllineitems}

\index{sentiment (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.sentiment}\pysigline{\bfcode{sentiment}}
Return a tuple of form (polarity, subjectivity ) where polarity
is a float within the range {[}-1.0, 1.0{]} and subjectivity is a float
within the range {[}0.0, 1.0{]} where 0.0 is very objective and 1.0 is
very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
named tuple of the form \code{Sentiment(polarity=0.0, subjectivity=0.0)}

\end{description}\end{quote}

\end{fulllineitems}

\index{serialized (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.serialized}\pysigline{\bfcode{serialized}}
Returns a list of each sentence's dict representation.

\end{fulllineitems}

\index{split() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.split}\pysiglinewithargsret{\bfcode{split}}{\emph{sep=None}, \emph{maxsplit=9223372036854775807}}{}
Behaves like the built-in str.split() except returns a
WordList.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
{\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{starts\_with() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.starts_with}\pysiglinewithargsret{\bfcode{starts\_with}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{startswith() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.startswith}\pysiglinewithargsret{\bfcode{startswith}}{\emph{prefix}, \emph{start=0}, \emph{end=9223372036854775807}}{}
Returns True if the blob starts with the given prefix.

\end{fulllineitems}

\index{strip() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.strip}\pysiglinewithargsret{\bfcode{strip}}{\emph{chars=None}}{}
Behaves like the built-in str.strip({[}chars{]}) method. Returns
an object with leading and trailing whitespace removed.

\end{fulllineitems}

\index{subjectivity (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.subjectivity}\pysigline{\bfcode{subjectivity}}
Return the subjectivity score as a float within the range {[}0.0, 1.0{]}
where 0.0 is very objective and 1.0 is very subjective.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
float

\end{description}\end{quote}

\end{fulllineitems}

\index{tags (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.tags}\pysigline{\bfcode{tags}}
Returns an list of tuples of the form (word, POS tag).

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{At}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{eight}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{CD}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{o}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{clock}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{JJ}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{IN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
        \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Thursday}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NNP}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{morning}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{NN}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{]}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{title() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.title}\pysiglinewithargsret{\bfcode{title}}{}{}
Returns a blob object with the text in title-case.

\end{fulllineitems}

\index{to\_json() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.to_json}\pysiglinewithargsret{\bfcode{to\_json}}{\emph{*args}, \emph{**kwargs}}{}
Return a json representation (str) of this blob. Takes the same
arguments as json.dumps.

\DUspan{versionmodified}{New in version 0.5.1: }(\code{textblob})

\end{fulllineitems}

\index{tokenize() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{tokenizer=None}}{}
Return a list of tokens, using \code{tokenizer}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer object. If None, defaults to
this blob's default tokenizer.

\end{description}\end{quote}

\end{fulllineitems}

\index{tokens (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.tokens}\pysigline{\bfcode{tokens}}
Return a list of tokens, using this blob's tokenizer object
(defaults to \code{WordTokenizer}).

\end{fulllineitems}

\index{translate() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.translate}\pysiglinewithargsret{\bfcode{translate}}{\emph{from\_lang=None}, \emph{to='de'}}{}
Translate the blob to another language.

\end{fulllineitems}

\index{upper() (textblob\_de.blob.TextBlobDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.upper}\pysiglinewithargsret{\bfcode{upper}}{}{}
Like str.upper(), returns new object with all upper-cased characters.

\end{fulllineitems}

\index{word\_counts (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.word_counts}\pysigline{\bfcode{word\_counts}}
Dictionary of word frequencies in this text.

\end{fulllineitems}

\index{words (textblob\_de.blob.TextBlobDE attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.TextBlobDE.words}\pysigline{\bfcode{words}}
Return a list of word tokens. This excludes punctuation characters.
If you want to include punctuation characters, access the \code{tokens}
property.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A {\hyperref[api_reference:textblob_de.blob.WordList]{\code{WordList}}} of word tokens.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{Word (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{Word}}{\emph{string}, \emph{pos\_tag=None}}{}
A simple word representation.

Includes methods for inflection, translation, and WordNet
integration.
\index{capitalize() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.capitalize}\pysiglinewithargsret{\bfcode{capitalize}}{}{{ $\rightarrow$ unicode}}
Return a capitalized version of S, i.e. make the first character
have upper case and the rest lower case.

\end{fulllineitems}

\index{center() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.center}\pysiglinewithargsret{\bfcode{center}}{\emph{width}\optional{, \emph{fillchar}}}{{ $\rightarrow$ unicode}}
Return S centered in a Unicode string of length width. Padding is
done using the specified fill character (default is a space)

\end{fulllineitems}

\index{correct() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.correct}\pysiglinewithargsret{\bfcode{correct}}{}{}
Correct the spelling of the word. Returns the word with the highest
confidence using the spelling corrector.

\DUspan{versionmodified}{New in version 0.6.0: }(\code{textblob})

\end{fulllineitems}

\index{count() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.count}\pysiglinewithargsret{\bfcode{count}}{\emph{sub}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ int}}
Return the number of non-overlapping occurrences of substring sub in
Unicode string S{[}start:end{]}.  Optional arguments start and end are
interpreted as in slice notation.

\end{fulllineitems}

\index{decode() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.decode}\pysiglinewithargsret{\bfcode{decode}}{\optional{\emph{encoding}\optional{, \emph{errors}}}}{{ $\rightarrow$ string or unicode}}
Decodes S using the codec registered for encoding. encoding defaults
to the default encoding. errors may be given to set a different error
handling scheme. Default is `strict' meaning that encoding errors raise
a UnicodeDecodeError. Other possible values are `ignore' and `replace'
as well as any other name registered with codecs.register\_error that is
able to handle UnicodeDecodeErrors.

\end{fulllineitems}

\index{define() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.define}\pysiglinewithargsret{\bfcode{define}}{\emph{pos=None}}{}
Return a list of definitions for this word. Each definition
corresponds to a synset for this word.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{pos} -- A part-of-speech tag to filter upon. If \code{None}, definitions
for all parts of speech will be loaded.

\item[{Return type}] \leavevmode
List of strings

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.7.0: }(\code{textblob})

\end{fulllineitems}

\index{definitions (textblob\_de.blob.Word attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.definitions}\pysigline{\bfcode{definitions}}
The list of definitions for this word. Each definition corresponds
to a synset.

\DUspan{versionmodified}{New in version 0.7.0: }(\code{textblob})

\end{fulllineitems}

\index{detect\_language() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.detect_language}\pysiglinewithargsret{\bfcode{detect\_language}}{}{}
Detect the word's language using Google's Translate API.

\DUspan{versionmodified}{New in version 0.5.0: }(\code{textblob})

\end{fulllineitems}

\index{encode() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.encode}\pysiglinewithargsret{\bfcode{encode}}{\optional{\emph{encoding}\optional{, \emph{errors}}}}{{ $\rightarrow$ string or unicode}}
Encodes S using the codec registered for encoding. encoding defaults
to the default encoding. errors may be given to set a different error
handling scheme. Default is `strict' meaning that encoding errors raise
a UnicodeEncodeError. Other possible values are `ignore', `replace' and
`xmlcharrefreplace' as well as any other name registered with
codecs.register\_error that can handle UnicodeEncodeErrors.

\end{fulllineitems}

\index{endswith() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.endswith}\pysiglinewithargsret{\bfcode{endswith}}{\emph{suffix}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ bool}}
Return True if S ends with the specified suffix, False otherwise.
With optional start, test S beginning at that position.
With optional end, stop comparing S at that position.
suffix can also be a tuple of strings to try.

\end{fulllineitems}

\index{expandtabs() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.expandtabs}\pysiglinewithargsret{\bfcode{expandtabs}}{\optional{\emph{tabsize}}}{{ $\rightarrow$ unicode}}
Return a copy of S where all tab characters are expanded using spaces.
If tabsize is not given, a tab size of 8 characters is assumed.

\end{fulllineitems}

\index{find() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.find}\pysiglinewithargsret{\bfcode{find}}{\emph{sub}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ int}}
Return the lowest index in S where substring sub is found,
such that sub is contained within S{[}start:end{]}.  Optional
arguments start and end are interpreted as in slice notation.

Return -1 on failure.

\end{fulllineitems}

\index{format() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.format}\pysiglinewithargsret{\bfcode{format}}{\emph{*args}, \emph{**kwargs}}{{ $\rightarrow$ unicode}}
Return a formatted version of S, using substitutions from args and kwargs.
The substitutions are identified by braces (`\{` and `\}').

\end{fulllineitems}

\index{get\_synsets() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.get_synsets}\pysiglinewithargsret{\bfcode{get\_synsets}}{\emph{pos=None}}{}
Return a list of Synset objects for this word.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{pos} -- A part-of-speech tag to filter upon. If \code{None}, all
synsets for all parts of speech will be loaded.

\item[{Return type}] \leavevmode
list of Synsets

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.7.0: }(\code{textblob})

\end{fulllineitems}

\index{index() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.index}\pysiglinewithargsret{\bfcode{index}}{\emph{sub}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ int}}
Like S.find() but raise ValueError when the substring is not found.

\end{fulllineitems}

\index{isalnum() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isalnum}\pysiglinewithargsret{\bfcode{isalnum}}{}{{ $\rightarrow$ bool}}
Return True if all characters in S are alphanumeric
and there is at least one character in S, False otherwise.

\end{fulllineitems}

\index{isalpha() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isalpha}\pysiglinewithargsret{\bfcode{isalpha}}{}{{ $\rightarrow$ bool}}
Return True if all characters in S are alphabetic
and there is at least one character in S, False otherwise.

\end{fulllineitems}

\index{isdecimal() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isdecimal}\pysiglinewithargsret{\bfcode{isdecimal}}{}{{ $\rightarrow$ bool}}
Return True if there are only decimal characters in S,
False otherwise.

\end{fulllineitems}

\index{isdigit() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isdigit}\pysiglinewithargsret{\bfcode{isdigit}}{}{{ $\rightarrow$ bool}}
Return True if all characters in S are digits
and there is at least one character in S, False otherwise.

\end{fulllineitems}

\index{islower() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.islower}\pysiglinewithargsret{\bfcode{islower}}{}{{ $\rightarrow$ bool}}
Return True if all cased characters in S are lowercase and there is
at least one cased character in S, False otherwise.

\end{fulllineitems}

\index{isnumeric() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isnumeric}\pysiglinewithargsret{\bfcode{isnumeric}}{}{{ $\rightarrow$ bool}}
Return True if there are only numeric characters in S,
False otherwise.

\end{fulllineitems}

\index{isspace() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isspace}\pysiglinewithargsret{\bfcode{isspace}}{}{{ $\rightarrow$ bool}}
Return True if all characters in S are whitespace
and there is at least one character in S, False otherwise.

\end{fulllineitems}

\index{istitle() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.istitle}\pysiglinewithargsret{\bfcode{istitle}}{}{{ $\rightarrow$ bool}}
Return True if S is a titlecased string and there is at least one
character in S, i.e. upper- and titlecase characters may only
follow uncased characters and lowercase characters only cased ones.
Return False otherwise.

\end{fulllineitems}

\index{isupper() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.isupper}\pysiglinewithargsret{\bfcode{isupper}}{}{{ $\rightarrow$ bool}}
Return True if all cased characters in S are uppercase and there is
at least one cased character in S, False otherwise.

\end{fulllineitems}

\index{join() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.join}\pysiglinewithargsret{\bfcode{join}}{\emph{iterable}}{{ $\rightarrow$ unicode}}
Return a string which is the concatenation of the strings in the
iterable.  The separator between elements is S.

\end{fulllineitems}

\index{lemma (textblob\_de.blob.Word attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.lemma}\pysigline{\bfcode{lemma}}
Return the lemma of this word using Wordnet's morphy function.

\end{fulllineitems}

\index{lemmatize() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.lemmatize}\pysiglinewithargsret{\bfcode{lemmatize}}{\emph{*args}, \emph{**kwargs}}{}
Return the lemma for a word using WordNet's morphy function.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{pos} -- Part of speech to filter upon. If \emph{None}, defaults to
\code{\_wordnet.NOUN}.

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.8.1: }(\code{textblob})

\end{fulllineitems}

\index{ljust() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.ljust}\pysiglinewithargsret{\bfcode{ljust}}{\emph{width}\optional{, \emph{fillchar}}}{{ $\rightarrow$ int}}
Return S left-justified in a Unicode string of length width. Padding is
done using the specified fill character (default is a space).

\end{fulllineitems}

\index{lower() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.lower}\pysiglinewithargsret{\bfcode{lower}}{}{{ $\rightarrow$ unicode}}
Return a copy of the string S converted to lowercase.

\end{fulllineitems}

\index{lstrip() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.lstrip}\pysiglinewithargsret{\bfcode{lstrip}}{\optional{\emph{chars}}}{{ $\rightarrow$ unicode}}
Return a copy of the string S with leading whitespace removed.
If chars is given and not None, remove characters in chars instead.
If chars is a str, it will be converted to unicode before stripping

\end{fulllineitems}

\index{partition() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.partition}\pysiglinewithargsret{\bfcode{partition}}{\emph{sep) -\textgreater{} (head}, \emph{sep}, \emph{tail}}{}
Search for the separator sep in S, and return the part before it,
the separator itself, and the part after it.  If the separator is not
found, return S and two empty strings.

\end{fulllineitems}

\index{pluralize() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.pluralize}\pysiglinewithargsret{\bfcode{pluralize}}{}{}
Return the plural version of the word as a string.

\end{fulllineitems}

\index{replace() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.replace}\pysiglinewithargsret{\bfcode{replace}}{\emph{old}, \emph{new}\optional{, \emph{count}}}{{ $\rightarrow$ unicode}}
Return a copy of S with all occurrences of substring
old replaced by new.  If the optional argument count is
given, only the first count occurrences are replaced.

\end{fulllineitems}

\index{rfind() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rfind}\pysiglinewithargsret{\bfcode{rfind}}{\emph{sub}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ int}}
Return the highest index in S where substring sub is found,
such that sub is contained within S{[}start:end{]}.  Optional
arguments start and end are interpreted as in slice notation.

Return -1 on failure.

\end{fulllineitems}

\index{rindex() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rindex}\pysiglinewithargsret{\bfcode{rindex}}{\emph{sub}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ int}}
Like S.rfind() but raise ValueError when the substring is not found.

\end{fulllineitems}

\index{rjust() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rjust}\pysiglinewithargsret{\bfcode{rjust}}{\emph{width}\optional{, \emph{fillchar}}}{{ $\rightarrow$ unicode}}
Return S right-justified in a Unicode string of length width. Padding is
done using the specified fill character (default is a space).

\end{fulllineitems}

\index{rpartition() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rpartition}\pysiglinewithargsret{\bfcode{rpartition}}{\emph{sep) -\textgreater{} (head}, \emph{sep}, \emph{tail}}{}
Search for the separator sep in S, starting at the end of S, and return
the part before it, the separator itself, and the part after it.  If the
separator is not found, return two empty strings and S.

\end{fulllineitems}

\index{rsplit() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rsplit}\pysiglinewithargsret{\bfcode{rsplit}}{\optional{\emph{sep}\optional{, \emph{maxsplit}}}}{{ $\rightarrow$ list of strings}}
Return a list of the words in S, using sep as the
delimiter string, starting at the end of the string and
working to the front.  If maxsplit is given, at most maxsplit
splits are done. If sep is not specified, any whitespace string
is a separator.

\end{fulllineitems}

\index{rstrip() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.rstrip}\pysiglinewithargsret{\bfcode{rstrip}}{\optional{\emph{chars}}}{{ $\rightarrow$ unicode}}
Return a copy of the string S with trailing whitespace removed.
If chars is given and not None, remove characters in chars instead.
If chars is a str, it will be converted to unicode before stripping

\end{fulllineitems}

\index{singularize() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.singularize}\pysiglinewithargsret{\bfcode{singularize}}{}{}
Return the singular version of the word as a string.

\end{fulllineitems}

\index{spellcheck() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.spellcheck}\pysiglinewithargsret{\bfcode{spellcheck}}{}{}
Return a list of (word, confidence) tuples of spelling corrections.

Based on: Peter Norvig, ``How to Write a Spelling Corrector''
(\href{http://norvig.com/spell-correct.html}{http://norvig.com/spell-correct.html}) as implemented in the pattern
library.

\DUspan{versionmodified}{New in version 0.6.0: }(\code{textblob})

\end{fulllineitems}

\index{split() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.split}\pysiglinewithargsret{\bfcode{split}}{\optional{\emph{sep}\optional{, \emph{maxsplit}}}}{{ $\rightarrow$ list of strings}}
Return a list of the words in S, using sep as the
delimiter string.  If maxsplit is given, at most maxsplit
splits are done. If sep is not specified or is None, any
whitespace string is a separator and empty strings are
removed from the result.

\end{fulllineitems}

\index{splitlines() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.splitlines}\pysiglinewithargsret{\bfcode{splitlines}}{\emph{keepends=False}}{{ $\rightarrow$ list of strings}}
Return a list of the lines in S, breaking at line boundaries.
Line breaks are not included in the resulting list unless keepends
is given and true.

\end{fulllineitems}

\index{startswith() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.startswith}\pysiglinewithargsret{\bfcode{startswith}}{\emph{prefix}\optional{, \emph{start}\optional{, \emph{end}}}}{{ $\rightarrow$ bool}}
Return True if S starts with the specified prefix, False otherwise.
With optional start, test S beginning at that position.
With optional end, stop comparing S at that position.
prefix can also be a tuple of strings to try.

\end{fulllineitems}

\index{strip() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.strip}\pysiglinewithargsret{\bfcode{strip}}{\optional{\emph{chars}}}{{ $\rightarrow$ unicode}}
Return a copy of the string S with leading and trailing
whitespace removed.
If chars is given and not None, remove characters in chars instead.
If chars is a str, it will be converted to unicode before stripping

\end{fulllineitems}

\index{swapcase() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.swapcase}\pysiglinewithargsret{\bfcode{swapcase}}{}{{ $\rightarrow$ unicode}}
Return a copy of S with uppercase characters converted to lowercase
and vice versa.

\end{fulllineitems}

\index{synsets (textblob\_de.blob.Word attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.synsets}\pysigline{\bfcode{synsets}}
The list of Synset objects for this Word.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list of Synsets

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.7.0: }(\code{textblob})

\end{fulllineitems}

\index{title() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.title}\pysiglinewithargsret{\bfcode{title}}{}{{ $\rightarrow$ unicode}}
Return a titlecased version of S, i.e. words start with title case
characters, all remaining cased characters have lower case.

\end{fulllineitems}

\index{translate() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.translate}\pysiglinewithargsret{\bfcode{translate}}{\emph{from\_lang=None}, \emph{to='de'}}{}
Translate the word to another language using Google's Translate API.

\DUspan{versionmodified}{New in version 0.5.0: }(\code{textblob})

\end{fulllineitems}

\index{upper() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.upper}\pysiglinewithargsret{\bfcode{upper}}{}{{ $\rightarrow$ unicode}}
Return a copy of S converted to uppercase.

\end{fulllineitems}

\index{zfill() (textblob\_de.blob.Word method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.Word.zfill}\pysiglinewithargsret{\bfcode{zfill}}{\emph{width}}{{ $\rightarrow$ unicode}}
Pad a numeric string S with zeros on the left, to fill a field
of the specified width. The string S is never truncated.

\end{fulllineitems}


\end{fulllineitems}

\index{WordList (class in textblob\_de.blob)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList}\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{WordList}}{\emph{collection}}{}
A list-like collection of words.
\index{append() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.append}\pysiglinewithargsret{\bfcode{append}}{\emph{obj}}{}
Append an object to end. If the object is a string, appends a.

{\hyperref[api_reference:textblob_de.blob.Word]{\code{Word}}} object.

\end{fulllineitems}

\index{count() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.count}\pysiglinewithargsret{\bfcode{count}}{\emph{strg}, \emph{case\_sensitive=False}, \emph{*args}, \emph{**kwargs}}{}
Get the count of a word or phrase \emph{s} within this WordList.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{strg} -- The string to count.

\item {} 
\textbf{case\_sensitive} -- A boolean, whether or not the search is case-sensitive.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{extend() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.extend}\pysiglinewithargsret{\bfcode{extend}}{\emph{iterable}}{}
Extend WordList by appending elements from \code{iterable}.

If an element
is a string, appends a {\hyperref[api_reference:textblob_de.blob.Word]{\code{Word}}} object.

\end{fulllineitems}

\index{index() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.index}\pysiglinewithargsret{\bfcode{index}}{\emph{value}\optional{, \emph{start}\optional{, \emph{stop}}}}{{ $\rightarrow$ integer -- return first index of value.}}
Raises ValueError if the value is not present.

\end{fulllineitems}

\index{insert() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.insert}\pysiglinewithargsret{\bfcode{insert}}{}{}
L.insert(index, object) -- insert object before index

\end{fulllineitems}

\index{lemmatize() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.lemmatize}\pysiglinewithargsret{\bfcode{lemmatize}}{}{}
Return the lemma of each word in this WordList.

Currently using NLTKPunktTokenizer() for all lemmatization
tasks. This might cause slightly different tokenization results
compared to the TextBlob.words property.

\end{fulllineitems}

\index{lower() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.lower}\pysiglinewithargsret{\bfcode{lower}}{}{}
Return a new WordList with each word lower-cased.

\end{fulllineitems}

\index{pluralize() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.pluralize}\pysiglinewithargsret{\bfcode{pluralize}}{}{}
Return the plural version of each word in this WordList.

\end{fulllineitems}

\index{pop() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.pop}\pysiglinewithargsret{\bfcode{pop}}{\optional{\emph{index}}}{{ $\rightarrow$ item -- remove and return item at index (default last).}}
Raises IndexError if list is empty or index is out of range.

\end{fulllineitems}

\index{remove() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.remove}\pysiglinewithargsret{\bfcode{remove}}{}{}
L.remove(value) -- remove first occurrence of value.
Raises ValueError if the value is not present.

\end{fulllineitems}

\index{reverse() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.reverse}\pysiglinewithargsret{\bfcode{reverse}}{}{}
L.reverse() -- reverse \emph{IN PLACE}

\end{fulllineitems}

\index{singularize() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.singularize}\pysiglinewithargsret{\bfcode{singularize}}{}{}
Return the single version of each word in this WordList.

\end{fulllineitems}

\index{sort() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.sort}\pysiglinewithargsret{\bfcode{sort}}{}{}
L.sort(cmp=None, key=None, reverse=False) -- stable sort \emph{IN PLACE};
cmp(x, y) -\textgreater{} -1, 0, 1

\end{fulllineitems}

\index{upper() (textblob\_de.blob.WordList method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.WordList.upper}\pysiglinewithargsret{\bfcode{upper}}{}{}
Return a new WordList with each word upper-cased.

\end{fulllineitems}


\end{fulllineitems}



\subsection{Base Classes}
\label{api_reference:base-classes}\label{api_reference:api-base-classes}\label{api_reference:module-textblob_de.base}\index{textblob\_de.base (module)}
Extensions to Abstract base classes in \code{textblob.base}
\index{BaseLemmatizer (class in textblob\_de.base)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.base.BaseLemmatizer}\pysigline{\strong{class }\code{textblob\_de.base.}\bfcode{BaseLemmatizer}}
Abstract base class from which all Lemmatizer classes inherit.
Descendant classes must implement a \code{lemmatize(text)} method that returns
a WordList of Word object with updated lemma properties.

\DUspan{versionmodified}{New in version 0.2.3: }(\code{textblob\_de})
\index{lemmatize() (textblob\_de.base.BaseLemmatizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.base.BaseLemmatizer.lemmatize}\pysiglinewithargsret{\bfcode{lemmatize}}{\emph{text}}{}
Return a list of (lemma, tag) tuples.

\end{fulllineitems}


\end{fulllineitems}



\subsection{Tokenizers}
\label{api_reference:tokenizers}\label{api_reference:module-textblob_de.tokenizers}\index{textblob\_de.tokenizers (module)}
Various tokenizer implementations.
\index{NLTKPunktTokenizer (class in textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.NLTKPunktTokenizer}\pysigline{\strong{class }\code{textblob\_de.tokenizers.}\bfcode{NLTKPunktTokenizer}}
Tokenizer included in \code{nltk.tokenize.punkt} package.

This is the default tokenizer in \code{textblob-de}

\textbf{PROs:}
\begin{itemize}
\item {} 
trained model available for German

\item {} 
deals with many abbreviations and common German tokenization problems oob

\end{itemize}

\textbf{CONs:}
\begin{itemize}
\item {} 
not very flexible (model has to be re-trained on your own corpus)

\end{itemize}
\index{itokenize() (textblob\_de.tokenizers.NLTKPunktTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.NLTKPunktTokenizer.itokenize}\pysiglinewithargsret{\bfcode{itokenize}}{\emph{text}, \emph{*args}, \emph{**kwargs}}{}
Return a generator that generates tokens ``on-demand''.

\DUspan{versionmodified}{New in version 0.6.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
generator

\end{description}\end{quote}

\end{fulllineitems}

\index{sent\_tokenize() (textblob\_de.tokenizers.NLTKPunktTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.NLTKPunktTokenizer.sent_tokenize}\pysiglinewithargsret{\bfcode{sent\_tokenize}}{\emph{*args}, \emph{**kwargs}}{}
NLTK's sentence tokenizer (currently PunktSentenceTokenizer).

Uses an unsupervised algorithm to build a model for abbreviation
words, collocations, and words that start sentences, then uses
that to find sentence boundaries.

\end{fulllineitems}

\index{tokenize() (textblob\_de.tokenizers.NLTKPunktTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.NLTKPunktTokenizer.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{text}, \emph{include\_punc=True}, \emph{nested=False}}{}
Return a list of word tokens.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} -- string of text.

\item {} 
\textbf{include\_punc} -- (optional) whether to include punctuation as separate
tokens. Default to True.

\item {} 
\textbf{nested} -- (optional) whether to return tokens as nested lists of
sentences. Default to False.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{word\_tokenize() (textblob\_de.tokenizers.NLTKPunktTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.NLTKPunktTokenizer.word_tokenize}\pysiglinewithargsret{\bfcode{word\_tokenize}}{\emph{text}, \emph{include\_punc=True}}{}
NLTK's PunktWordTokenizer uses a regular expression to divide a text
into tokens, leaving all periods attached to words, but separating off
other punctuation.

\end{fulllineitems}


\end{fulllineitems}

\index{PatternTokenizer (class in textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.PatternTokenizer}\pysigline{\strong{class }\code{textblob\_de.tokenizers.}\bfcode{PatternTokenizer}}
Tokenizer included in \code{pattern.de} package.

\textbf{PROs:}
\begin{itemize}
\item {} 
handling of emoticons

\item {} 
flexible implementations of abbreviations

\item {} 
can be adapted very easily

\end{itemize}

\textbf{CONs:}
\begin{itemize}
\item {} 
ordinal numbers cause sentence breaks

\item {} 
indices of Sentence() objects cannot be computed

\end{itemize}
\index{itokenize() (textblob\_de.tokenizers.PatternTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.PatternTokenizer.itokenize}\pysiglinewithargsret{\bfcode{itokenize}}{\emph{text}, \emph{*args}, \emph{**kwargs}}{}
Return a generator that generates tokens ``on-demand''.

\DUspan{versionmodified}{New in version 0.6.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
generator

\end{description}\end{quote}

\end{fulllineitems}

\index{sent\_tokenize() (textblob\_de.tokenizers.PatternTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.PatternTokenizer.sent_tokenize}\pysiglinewithargsret{\bfcode{sent\_tokenize}}{\emph{text}, \emph{**kwargs}}{}
Returns a list of sentences.

Each sentence is a space-separated string of tokens (words).
Handles common cases of abbreviations (e.g., etc., ...).
Punctuation marks are split from other words. Periods (or ?!) mark the end of a sentence.
Headings without an ending period are inferred by line breaks.

\end{fulllineitems}

\index{tokenize() (textblob\_de.tokenizers.PatternTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.PatternTokenizer.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{text}, \emph{include\_punc=True}, \emph{nested=False}}{}
Return a list of word tokens.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} -- string of text.

\item {} 
\textbf{include\_punc} -- (optional) whether to include punctuation as separate
tokens. Default to True.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{SentenceTokenizer (class in textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.SentenceTokenizer}\pysiglinewithargsret{\strong{class }\code{textblob\_de.tokenizers.}\bfcode{SentenceTokenizer}}{\emph{tokenizer=None}, \emph{*args}, \emph{**kwargs}}{}
Generic sentence tokenization class, using tokenizer specified in
TextBlobDE() instance.

Enables SentenceTokenizer().itokenize generator that would be lost otherwise.

Aim: Not to break core API of the main \href{http://textblob.readthedocs.org/}{TextBlob} library.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\end{description}\end{quote}
\index{itokenize() (textblob\_de.tokenizers.SentenceTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.SentenceTokenizer.itokenize}\pysiglinewithargsret{\bfcode{itokenize}}{\emph{text}, \emph{*args}, \emph{**kwargs}}{}
Return a generator that generates tokens ``on-demand''.

\DUspan{versionmodified}{New in version 0.6.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
generator

\end{description}\end{quote}

\end{fulllineitems}

\index{sent\_tokenize() (textblob\_de.tokenizers.SentenceTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.SentenceTokenizer.sent_tokenize}\pysiglinewithargsret{\bfcode{sent\_tokenize}}{\emph{text}, \emph{**kwargs}}{}
Compatibility method to tokenizers included in \code{textblob-de}

\end{fulllineitems}

\index{tokenize() (textblob\_de.tokenizers.SentenceTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.SentenceTokenizer.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{text}, \emph{**kwargs}}{}
Return a list of word tokens.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} -- string of text.

\item {} 
\textbf{include\_punc} -- (optional) whether to include punctuation as separate
tokens. Default to True.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{WordTokenizer (class in textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.WordTokenizer}\pysiglinewithargsret{\strong{class }\code{textblob\_de.tokenizers.}\bfcode{WordTokenizer}}{\emph{tokenizer=None}, \emph{*args}, \emph{**kwargs}}{}
Generic word tokenization class, using tokenizer specified in
TextBlobDE() instance.

You can also submit the tokenizer as keyword argument:
\code{WordTokenizer(tokenizer=NLTKPunktTokenizer())}

Enables WordTokenizer().itokenize generator that would be lost otherwise.

Default: NLTKPunktTokenizer().word\_tokenize(text, include\_punc=True)

Aim: Not to break core API of the main \href{http://textblob.readthedocs.org/}{TextBlob} library.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\end{description}\end{quote}
\index{itokenize() (textblob\_de.tokenizers.WordTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.WordTokenizer.itokenize}\pysiglinewithargsret{\bfcode{itokenize}}{\emph{text}, \emph{*args}, \emph{**kwargs}}{}
Return a generator that generates tokens ``on-demand''.

\DUspan{versionmodified}{New in version 0.6.0.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
generator

\end{description}\end{quote}

\end{fulllineitems}

\index{tokenize() (textblob\_de.tokenizers.WordTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.WordTokenizer.tokenize}\pysiglinewithargsret{\bfcode{tokenize}}{\emph{text}, \emph{include\_punc=True}, \emph{**kwargs}}{}
Return a list of word tokens.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} -- string of text.

\item {} 
\textbf{include\_punc} -- (optional) whether to include punctuation as separate
tokens. Default to True.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{word\_tokenize() (textblob\_de.tokenizers.WordTokenizer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.WordTokenizer.word_tokenize}\pysiglinewithargsret{\bfcode{word\_tokenize}}{\emph{text}, \emph{include\_punc=True}}{}
Compatibility method to tokenizers included in \code{textblob-de}

\end{fulllineitems}


\end{fulllineitems}

\index{sent\_tokenize() (in module textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.sent_tokenize}\pysiglinewithargsret{\code{textblob\_de.tokenizers.}\bfcode{sent\_tokenize}}{\emph{text}, \emph{tokenizer=None}}{}
Convenience function for tokenizing sentences (not iterable).

If tokenizer is not specified, the default tokenizer NLTKPunktTokenizer()
is used (same behaviour as in the main \href{http://textblob.readthedocs.org/}{TextBlob} library).

This function returns the sentences as a generator object.

\end{fulllineitems}

\index{word\_tokenize() (in module textblob\_de.tokenizers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.tokenizers.word_tokenize}\pysiglinewithargsret{\code{textblob\_de.tokenizers.}\bfcode{word\_tokenize}}{\emph{text}, \emph{tokenizer=None}, \emph{include\_punc=True}, \emph{*args}, \emph{**kwargs}}{}
Convenience function for tokenizing text into words.

NOTE: NLTK's word tokenizer expects sentences as input, so the text will be
tokenized to sentences before being tokenized to words.

This function returns an itertools chain object (generator).

\end{fulllineitems}



\subsection{POS Taggers}
\label{api_reference:pos-taggers}\label{api_reference:module-textblob_de.taggers}\index{textblob\_de.taggers (module)}
Default taggers for German.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.taggers} \PYG{k+kn}{import} \PYG{n}{PatternTagger}
\end{Verbatim}

or

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{PatternTagger}
\end{Verbatim}
\index{PatternTagger (class in textblob\_de.taggers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.taggers.PatternTagger}\pysiglinewithargsret{\strong{class }\code{textblob\_de.taggers.}\bfcode{PatternTagger}}{\emph{tokenizer=None}, \emph{include\_punc=False}}{}
Tagger that uses the implementation in
Tom de Smedt's pattern library
(\href{http://www.clips.ua.ac.be/pattern}{http://www.clips.ua.ac.be/pattern}).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.PatternTokenizer]{\code{PatternTokenizer()}}}.

\item {} 
\textbf{include\_punc} -- (optional) whether to include punctuation as separate tokens.
Default to \code{False}.

\end{itemize}

\end{description}\end{quote}
\index{tag() (textblob\_de.taggers.PatternTagger method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.taggers.PatternTagger.tag}\pysiglinewithargsret{\bfcode{tag}}{\emph{sentence}, \emph{tokenize=True}}{}
Tag a string \emph{sentence}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{or list sentence} (\emph{str}) -- A string or a list of sentence strings.

\item {} 
\textbf{tokenize} -- (optional) If \code{False} string has to be tokenized before
(space separated string).

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{Noun Phrase Extractors}
\label{api_reference:module-textblob_de.np_extractors}\label{api_reference:noun-phrase-extractors}\index{textblob\_de.np\_extractors (module)}
Various noun phrase extractor implementations.

\# {\hyperref[api_reference:textblob_de.np_extractors.PatternParserNPExtractor]{\code{PatternParserNPExtractor()}}}.
\index{PatternParserNPExtractor (class in textblob\_de.np\_extractors)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.np_extractors.PatternParserNPExtractor}\pysiglinewithargsret{\strong{class }\code{textblob\_de.np\_extractors.}\bfcode{PatternParserNPExtractor}}{\emph{tokenizer=None}}{}
Extract noun phrases (NP) from PatternParser() output.

Very naïve and resource hungry approach:
\begin{itemize}
\item {} 
get parser output

\item {} 
try to correct as many obvious parser errors as you can (e.g. eliminate wrongly tagged verbs)

\item {} 
filter insignificant words

\end{itemize}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.PatternTokenizer]{\code{PatternTokenizer()}}}.

\end{description}\end{quote}
\index{extract() (textblob\_de.np\_extractors.PatternParserNPExtractor method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.np_extractors.PatternParserNPExtractor.extract}\pysiglinewithargsret{\bfcode{extract}}{\emph{text}}{}
Return a list of noun phrases (strings) for a body of text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{Sentiment Analyzers}
\label{api_reference:sentiment-analyzers}\label{api_reference:module-textblob_de.sentiments}\index{textblob\_de.sentiments (module)}
German sentiment analysis implementations.

Main resource for \code{de-sentiment.xml}:
\begin{itemize}
\item {} 
\href{http://bics.sentimental.li/index.php/downloads}{German Polarity Lexicon}

\item {} 
See xml comment section in \code{de-sentiment.xml} for details

\end{itemize}
\index{PatternAnalyzer (class in textblob\_de.sentiments)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.sentiments.PatternAnalyzer}\pysiglinewithargsret{\strong{class }\code{textblob\_de.sentiments.}\bfcode{PatternAnalyzer}}{\emph{tokenizer=None}, \emph{lemmatizer=None}, \emph{lemmatize=True}}{}
Sentiment analyzer that uses the same implementation as the
pattern library. Returns results as a tuple of the form:

\code{(polarity, subjectivity)}
\index{RETURN\_TYPE (textblob\_de.sentiments.PatternAnalyzer attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.sentiments.PatternAnalyzer.RETURN_TYPE}\pysigline{\bfcode{RETURN\_TYPE}}
Return type declaration

alias of \code{Sentiment}

\end{fulllineitems}

\index{analyze() (textblob\_de.sentiments.PatternAnalyzer method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.sentiments.PatternAnalyzer.analyze}\pysiglinewithargsret{\bfcode{analyze}}{\emph{text}}{}
Return the sentiment as a tuple of the form:
\code{(polarity, subjectivity)}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string.

\end{description}\end{quote}

\end{fulllineitems}

\index{kind (textblob\_de.sentiments.PatternAnalyzer attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.sentiments.PatternAnalyzer.kind}\pysigline{\bfcode{kind}\strong{ = `co'}}
adapted from `textblob.en.sentiments.py'

\end{fulllineitems}


\end{fulllineitems}



\subsection{Parsers}
\label{api_reference:parsers}\label{api_reference:module-textblob_de.parsers}\index{textblob\_de.parsers (module)}
Default parsers for German.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.parsers} \PYG{k+kn}{import} \PYG{n}{PatternParser}
\end{Verbatim}

or

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{PatternParser}
\end{Verbatim}
\index{PatternParser (class in textblob\_de.parsers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.parsers.PatternParser}\pysiglinewithargsret{\strong{class }\code{textblob\_de.parsers.}\bfcode{PatternParser}}{\emph{tokenizer=None}, \emph{tokenize=True}, \emph{pprint=False}, \emph{tags=True}, \emph{chunks=True}, \emph{relations=False}, \emph{lemmata=False}, \emph{encoding='utf-8'}, \emph{tagset=None}}{}
Parser that uses the implementation in Tom de Smedt's pattern library.
\href{http://www.clips.ua.ac.be/pages/pattern-de\#parser}{http://www.clips.ua.ac.be/pages/pattern-de\#parser}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.PatternTokenizer]{\code{PatternTokenizer()}}}.

\item {} 
\textbf{tokenize} -- (optional) Split punctuation marks from words? (Default \code{True})

\item {} 
\textbf{pprint} -- (optional) Use \code{pattern}`s \code{pprint} function to display parse
trees (Default \code{False})

\item {} 
\textbf{tags} -- (optional) Parse part-of-speech tags? (NN, JJ, ...) (Default \code{True})

\item {} 
\textbf{chunks} -- (optional) Parse chunks? (NP, VP, PNP, ...) (Default \code{True})

\item {} 
\textbf{relations} -- (optional) Parse chunk relations? (-SBJ, -OBJ, ...) (Default \code{False})

\item {} 
\textbf{lemmata} -- (optional) Parse lemmata? (schönes =\textgreater{} schön) (Default \code{False})

\item {} 
\textbf{encoding} -- (optional) Input string encoding. (Default \code{utf-8})

\item {} 
\textbf{tagset} -- (optional) Penn Treebank II (default) or (`penn'\textbar{}'universal'\textbar{}'stts').

\end{itemize}

\end{description}\end{quote}
\index{parse() (textblob\_de.parsers.PatternParser method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.parsers.PatternParser.parse}\pysiglinewithargsret{\bfcode{parse}}{\emph{text}}{}
Parses the text.

\code{pattern.de.parse(**kwargs)} can be passed to the parser instance and
are documented in the main docstring of
{\hyperref[api_reference:textblob_de.parsers.PatternParser]{\code{PatternParser()}}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string.

\end{description}\end{quote}

\end{fulllineitems}

\index{parsetree() (textblob\_de.parsers.PatternParser method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.parsers.PatternParser.parsetree}\pysiglinewithargsret{\bfcode{parsetree}}{\emph{text}}{}
Returns a parsed \code{pattern} Text object from the given string.

\end{fulllineitems}


\end{fulllineitems}



\subsection{Classifiers (from TextBlob main package)}
\label{api_reference:module-textblob.classifiers}\label{api_reference:classifiers-from-textblob-main-package}\label{api_reference:api-classifiers}\index{textblob.classifiers (module)}
Various classifier implementations. Also includes basic feature extractor
methods.

Example Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob} \PYG{k+kn}{import} \PYG{n}{TextBlob}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob.classifiers} \PYG{k+kn}{import} \PYG{n}{NaiveBayesClassifier}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{train} \PYG{o}{=} \PYG{p}{[}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I love this sandwich.}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{pos}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{This is an amazing place!}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{pos}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I feel very good about these beers.}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{pos}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I do not like this restaurant}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{neg}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I am tired of this stuff.}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{neg}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I can}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{t deal with this}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{neg}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{g+gp}{... }    \PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My boss is horrible.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{neg}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{... }\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cl} \PYG{o}{=} \PYG{n}{NaiveBayesClassifier}\PYG{p}{(}\PYG{n}{train}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{cl}\PYG{o}{.}\PYG{n}{classify}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I feel amazing!}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{\PYGZsq{}pos\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob} \PYG{o}{=} \PYG{n}{TextBlob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{The beer is good. But the hangover is horrible.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{classifier}\PYG{o}{=}\PYG{n}{cl}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{for} \PYG{n}{s} \PYG{o+ow}{in} \PYG{n}{blob}\PYG{o}{.}\PYG{n}{sentences}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{k}{print}\PYG{p}{(}\PYG{n}{s}\PYG{p}{)}
\PYG{g+gp}{... }    \PYG{k}{print}\PYG{p}{(}\PYG{n}{s}\PYG{o}{.}\PYG{n}{classify}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{...}
\PYG{g+go}{The beer is good.}
\PYG{g+go}{pos}
\PYG{g+go}{But the hangover is horrible.}
\PYG{g+go}{neg}
\end{Verbatim}

\DUspan{versionmodified}{New in version 0.6.0.}
\index{BaseClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{BaseClassifier}}{\emph{train\_set}, \emph{feature\_extractor=\textless{}function basic\_extractor at 0x2b1f17c231b8\textgreater{}}, \emph{format=None}, \emph{**kwargs}}{}
Abstract classifier class from which all classifers inherit. At a
minimum, descendant classes must implement a \code{classify} method and have
a \code{classifier} property.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{train\_set} -- The training set, either a list of tuples of the form
\code{(text, classification)} or a file-like object. \code{text} may be either
a string or an iterable.

\item {} 
\textbf{feature\_extractor} (\emph{callable}) -- A feature extractor function that takes one or
two arguments: \code{document} and \code{train\_set}.

\item {} 
\textbf{format} (\emph{str}) -- If \code{train\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\item {} 
\textbf{kwargs} -- Additional keyword arguments are passed to the constructor
of the {\hyperref[api_reference:textblob.formats.BaseFormat]{\code{Format}}} class used to
read the data. Only applies when a file-like object is passed as
\code{train\_set}.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.0.}
\index{classifier (textblob.classifiers.BaseClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier object.

\end{fulllineitems}

\index{classify() (textblob.classifiers.BaseClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies a string of text.

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.BaseClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.BaseClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Returns an iterable containing the possible labels.

\end{fulllineitems}

\index{train() (textblob.classifiers.BaseClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.BaseClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{labeled\_featureset}}{}
Trains the classifier.

\end{fulllineitems}


\end{fulllineitems}

\index{DecisionTreeClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{DecisionTreeClassifier}}{\emph{train\_set}, \emph{feature\_extractor=\textless{}function basic\_extractor at 0x2b1f17c231b8\textgreater{}}, \emph{format=None}, \emph{**kwargs}}{}
A classifier based on the decision tree algorithm, as implemented in
NLTK.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{train\_set} -- The training set, either a list of tuples of the form
\code{(text, classification)} or a filename. \code{text} may be either
a string or an iterable.

\item {} 
\textbf{feature\_extractor} -- A feature extractor function that takes one or
two arguments: \code{document} and \code{train\_set}.

\item {} 
\textbf{format} -- If \code{train\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.2.}
\index{accuracy() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.accuracy}\pysiglinewithargsret{\bfcode{accuracy}}{\emph{test\_set}, \emph{format=None}}{}
Compute the accuracy on a test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{test\_set} -- A list of tuples of the form \code{(text, label)}, or a
file pointer.

\item {} 
\textbf{format} -- If \code{test\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{classifier (textblob.classifiers.DecisionTreeClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier.

\end{fulllineitems}

\index{classify() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string of text.

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Return an iterable of possible labels.

\end{fulllineitems}

\index{pprint() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.pprint}\pysiglinewithargsret{\bfcode{pprint}}{\emph{*args}, \emph{**kwargs}}{}
Return a string containing a pretty-printed version of this decision
tree. Each line in the string corresponds to a single decision tree node
or leaf, and indentation is used to display the structure of the tree.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{pseudocode() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.pseudocode}\pysiglinewithargsret{\bfcode{pseudocode}}{\emph{*args}, \emph{**kwargs}}{}
Return a string representation of this decision tree that expresses
the decisions it makes as a nested set of pseudocode if statements.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{train() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{*args}, \emph{**kwargs}}{}
Train the classifier with a labeled feature set and return
the classifier. Takes the same arguments as the wrapped NLTK class.
This method is implicitly called when calling \code{classify} or
\code{accuracy} methods and is included only to allow passing in arguments
to the \code{train} method of the wrapped NLTK class.

\DUspan{versionmodified}{New in version 0.6.2.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
A classifier

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (textblob.classifiers.DecisionTreeClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.DecisionTreeClassifier.update}\pysiglinewithargsret{\bfcode{update}}{\emph{new\_data}, \emph{*args}, \emph{**kwargs}}{}
Update the classifier with new training data and re-trains the
classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{new\_data} -- New data as a list of tuples of the form
\code{(text, label)}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{MaxEntClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{MaxEntClassifier}}{\emph{train\_set}, \emph{feature\_extractor=\textless{}function basic\_extractor at 0x2b1f17c231b8\textgreater{}}, \emph{format=None}, \emph{**kwargs}}{}
A maximum entropy classifier (also known as a ``conditional
exponential classifier'').  This classifier is parameterized by a
set of ``weights'', which are used to combine the joint-features
that are generated from a featureset by an ``encoding''.  In
particular, the encoding maps each \code{(featureset, label)} pair to
a vector.  The probability of each label is then computed using
the following equation:

\begin{Verbatim}[commandchars=\\\{\}]
                          dotprod(weights, encode(fs,label))
prob(fs\textbar{}label) = \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
                 sum(dotprod(weights, encode(fs,l)) for l in labels)
\end{Verbatim}

Where \code{dotprod} is the dot product:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{dotprod}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,}\PYG{n}{b}\PYG{p}{)} \PYG{o}{=} \PYG{n+nb}{sum}\PYG{p}{(}\PYG{n}{x}\PYG{o}{*}\PYG{n}{y} \PYG{k}{for} \PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{y}\PYG{p}{)} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{a}\PYG{p}{,}\PYG{n}{b}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}
\index{accuracy() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.accuracy}\pysiglinewithargsret{\bfcode{accuracy}}{\emph{test\_set}, \emph{format=None}}{}
Compute the accuracy on a test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{test\_set} -- A list of tuples of the form \code{(text, label)}, or a
file pointer.

\item {} 
\textbf{format} -- If \code{test\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{classifier (textblob.classifiers.MaxEntClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier.

\end{fulllineitems}

\index{classify() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string of text.

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Return an iterable of possible labels.

\end{fulllineitems}

\index{nltk\_class (textblob.classifiers.MaxEntClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.nltk_class}\pysigline{\bfcode{nltk\_class}}
alias of \code{MaxentClassifier}

\end{fulllineitems}

\index{prob\_classify() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.prob_classify}\pysiglinewithargsret{\bfcode{prob\_classify}}{\emph{text}}{}
Return the label probability distribution for classifying a string
of text.

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier} \PYG{o}{=} \PYG{n}{MaxEntClassifier}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist} \PYG{o}{=} \PYG{n}{classifier}\PYG{o}{.}\PYG{n}{prob\PYGZus{}classify}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I feel happy this morning.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{\PYGZsq{}positive\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist}\PYG{o}{.}\PYG{n}{prob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{positive}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{0.7}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
nltk.probability.DictionaryProbDist

\end{description}\end{quote}

\end{fulllineitems}

\index{train() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{*args}, \emph{**kwargs}}{}
Train the classifier with a labeled feature set and return
the classifier. Takes the same arguments as the wrapped NLTK class.
This method is implicitly called when calling \code{classify} or
\code{accuracy} methods and is included only to allow passing in arguments
to the \code{train} method of the wrapped NLTK class.

\DUspan{versionmodified}{New in version 0.6.2.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
A classifier

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (textblob.classifiers.MaxEntClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.MaxEntClassifier.update}\pysiglinewithargsret{\bfcode{update}}{\emph{new\_data}, \emph{*args}, \emph{**kwargs}}{}
Update the classifier with new training data and re-trains the
classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{new\_data} -- New data as a list of tuples of the form
\code{(text, label)}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{NLTKClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{NLTKClassifier}}{\emph{train\_set}, \emph{feature\_extractor=\textless{}function basic\_extractor at 0x2b1f17c231b8\textgreater{}}, \emph{format=None}, \emph{**kwargs}}{}
An abstract class that wraps around the nltk.classify module.

Expects that descendant classes include a class variable \code{nltk\_class}
which is the class in the nltk.classify module to be wrapped.

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{class} \PYG{n+nc}{MyClassifier}\PYG{p}{(}\PYG{n}{NLTKClassifier}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{nltk\PYGZus{}class} \PYG{o}{=} \PYG{n}{nltk}\PYG{o}{.}\PYG{n}{classify}\PYG{o}{.}\PYG{n}{svm}\PYG{o}{.}\PYG{n}{SvmClassifier}
\end{Verbatim}
\index{accuracy() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.accuracy}\pysiglinewithargsret{\bfcode{accuracy}}{\emph{test\_set}, \emph{format=None}}{}
Compute the accuracy on a test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{test\_set} -- A list of tuples of the form \code{(text, label)}, or a
file pointer.

\item {} 
\textbf{format} -- If \code{test\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{classifier (textblob.classifiers.NLTKClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier.

\end{fulllineitems}

\index{classify() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string of text.

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Return an iterable of possible labels.

\end{fulllineitems}

\index{nltk\_class (textblob.classifiers.NLTKClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.nltk_class}\pysigline{\bfcode{nltk\_class}\strong{ = None}}
The NLTK class to be wrapped. Must be a class within nltk.classify

\end{fulllineitems}

\index{train() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{*args}, \emph{**kwargs}}{}
Train the classifier with a labeled feature set and return
the classifier. Takes the same arguments as the wrapped NLTK class.
This method is implicitly called when calling \code{classify} or
\code{accuracy} methods and is included only to allow passing in arguments
to the \code{train} method of the wrapped NLTK class.

\DUspan{versionmodified}{New in version 0.6.2.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
A classifier

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (textblob.classifiers.NLTKClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NLTKClassifier.update}\pysiglinewithargsret{\bfcode{update}}{\emph{new\_data}, \emph{*args}, \emph{**kwargs}}{}
Update the classifier with new training data and re-trains the
classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{new\_data} -- New data as a list of tuples of the form
\code{(text, label)}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{NaiveBayesClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{NaiveBayesClassifier}}{\emph{train\_set}, \emph{feature\_extractor=\textless{}function basic\_extractor at 0x2b1f17c231b8\textgreater{}}, \emph{format=None}, \emph{**kwargs}}{}
A classifier based on the Naive Bayes algorithm, as implemented in
NLTK.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{train\_set} -- The training set, either a list of tuples of the form
\code{(text, classification)} or a filename. \code{text} may be either
a string or an iterable.

\item {} 
\textbf{feature\_extractor} -- A feature extractor function that takes one or
two arguments: \code{document} and \code{train\_set}.

\item {} 
\textbf{format} -- If \code{train\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.6.0.}
\index{accuracy() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.accuracy}\pysiglinewithargsret{\bfcode{accuracy}}{\emph{test\_set}, \emph{format=None}}{}
Compute the accuracy on a test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{test\_set} -- A list of tuples of the form \code{(text, label)}, or a
file pointer.

\item {} 
\textbf{format} -- If \code{test\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{classifier (textblob.classifiers.NaiveBayesClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier.

\end{fulllineitems}

\index{classify() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string of text.

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{informative\_features() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.informative_features}\pysiglinewithargsret{\bfcode{informative\_features}}{\emph{*args}, \emph{**kwargs}}{}
Return the most informative features as a list of tuples of the
form \code{(feature\_name, feature\_value)}.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
list

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Return an iterable of possible labels.

\end{fulllineitems}

\index{nltk\_class (textblob.classifiers.NaiveBayesClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.nltk_class}\pysigline{\bfcode{nltk\_class}}
alias of {\hyperref[api_reference:textblob.classifiers.NaiveBayesClassifier]{\code{NaiveBayesClassifier}}}

\end{fulllineitems}

\index{prob\_classify() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.prob_classify}\pysiglinewithargsret{\bfcode{prob\_classify}}{\emph{text}}{}
Return the label probability distribution for classifying a string
of text.

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier} \PYG{o}{=} \PYG{n}{NaiveBayesClassifier}\PYG{p}{(}\PYG{n}{train\PYGZus{}data}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist} \PYG{o}{=} \PYG{n}{classifier}\PYG{o}{.}\PYG{n}{prob\PYGZus{}classify}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I feel happy this morning.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)}
\PYG{g+go}{\PYGZsq{}positive\PYGZsq{}}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{prob\PYGZus{}dist}\PYG{o}{.}\PYG{n}{prob}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{positive}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{0.7}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
nltk.probability.DictionaryProbDist

\end{description}\end{quote}

\end{fulllineitems}

\index{show\_informative\_features() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.show_informative_features}\pysiglinewithargsret{\bfcode{show\_informative\_features}}{\emph{*args}, \emph{**kwargs}}{}
Displays a listing of the most informative features for this
classifier.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
None

\end{description}\end{quote}

\end{fulllineitems}

\index{train() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{*args}, \emph{**kwargs}}{}
Train the classifier with a labeled feature set and return
the classifier. Takes the same arguments as the wrapped NLTK class.
This method is implicitly called when calling \code{classify} or
\code{accuracy} methods and is included only to allow passing in arguments
to the \code{train} method of the wrapped NLTK class.

\DUspan{versionmodified}{New in version 0.6.2.}
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
A classifier

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (textblob.classifiers.NaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.NaiveBayesClassifier.update}\pysiglinewithargsret{\bfcode{update}}{\emph{new\_data}, \emph{*args}, \emph{**kwargs}}{}
Update the classifier with new training data and re-trains the
classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{new\_data} -- New data as a list of tuples of the form
\code{(text, label)}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{PositiveNaiveBayesClassifier (class in textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier}\pysiglinewithargsret{\strong{class }\code{textblob.classifiers.}\bfcode{PositiveNaiveBayesClassifier}}{\emph{positive\_set}, \emph{unlabeled\_set}, \emph{feature\_extractor=\textless{}function contains\_extractor at 0x2b1f17c23230\textgreater{}}, \emph{positive\_prob\_prior=0.5}, \emph{**kwargs}}{}
A variant of the Naive Bayes Classifier that performs binary
classification with partially-labeled training sets, i.e. when only
one class is labeled and the other is not. Assuming a prior distribution
on the two labels, uses the unlabeled set to estimate the frequencies of
the features.

Example usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{text.classifiers} \PYG{k+kn}{import} \PYG{n}{PositiveNaiveBayesClassifier}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{sports\PYGZus{}sentences} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The team dominated the game}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{They lost the ball}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The game was intense}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The goalkeeper catched the ball}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The other team controlled the ball}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{various\PYGZus{}sentences} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The President did not comment}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I lost the keys}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The team won the game}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Sara has two kids}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The ball went off the court}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{They had the ball for the whole game}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
\PYG{g+gp}{... }                       \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{The show is over}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier} \PYG{o}{=} \PYG{n}{PositiveNaiveBayesClassifier}\PYG{p}{(}\PYG{n}{positive\PYGZus{}set}\PYG{o}{=}\PYG{n}{sports\PYGZus{}sentences}\PYG{p}{,}
\PYG{g+gp}{... }                                          \PYG{n}{unlabeled\PYGZus{}set}\PYG{o}{=}\PYG{n}{various\PYGZus{}sentences}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier}\PYG{o}{.}\PYG{n}{classify}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My team lost the game}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{True}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{classifier}\PYG{o}{.}\PYG{n}{classify}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{And now for something completely different.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+go}{False}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{positive\_set} -- A collection of strings that have the positive label.

\item {} 
\textbf{unlabeled\_set} -- A collection of unlabeled strings.

\item {} 
\textbf{feature\_extractor} -- A feature extractor function.

\item {} 
\textbf{positive\_prob\_prior} -- A prior estimate of the probability of the
label \code{True}.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.7.0.}
\index{accuracy() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.accuracy}\pysiglinewithargsret{\bfcode{accuracy}}{\emph{test\_set}, \emph{format=None}}{}
Compute the accuracy on a test set.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{test\_set} -- A list of tuples of the form \code{(text, label)}, or a
file pointer.

\item {} 
\textbf{format} -- If \code{test\_set} is a filename, the file format, e.g.
\code{"csv"} or \code{"json"}. If \code{None}, will attempt to detect the
file format.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{classifier (textblob.classifiers.PositiveNaiveBayesClassifier attribute)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.classifier}\pysigline{\bfcode{classifier}}
The classifier.

\end{fulllineitems}

\index{classify() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.classify}\pysiglinewithargsret{\bfcode{classify}}{\emph{text}}{}
Classifies the text.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{text} (\emph{str}) -- A string of text.

\end{description}\end{quote}

\end{fulllineitems}

\index{extract\_features() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.extract_features}\pysiglinewithargsret{\bfcode{extract\_features}}{\emph{text}}{}
Extracts features from a body of text.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
dictionary of features

\end{description}\end{quote}

\end{fulllineitems}

\index{labels() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.labels}\pysiglinewithargsret{\bfcode{labels}}{}{}
Return an iterable of possible labels.

\end{fulllineitems}

\index{train() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.train}\pysiglinewithargsret{\bfcode{train}}{\emph{*args}, \emph{**kwargs}}{}
Train the classifier with a labeled and unlabeled feature sets and return
the classifier. Takes the same arguments as the wrapped NLTK class.
This method is implicitly called when calling \code{classify} or
\code{accuracy} methods and is included only to allow passing in arguments
to the \code{train} method of the wrapped NLTK class.
\begin{quote}\begin{description}
\item[{Return type}] \leavevmode
A classifier

\end{description}\end{quote}

\end{fulllineitems}

\index{update() (textblob.classifiers.PositiveNaiveBayesClassifier method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.PositiveNaiveBayesClassifier.update}\pysiglinewithargsret{\bfcode{update}}{\emph{new\_positive\_data=None}, \emph{new\_unlabeled\_data=None}, \emph{positive\_prob\_prior=0.5}, \emph{*args}, \emph{**kwargs}}{}
Update the classifier with new data and re-trains the
classifier.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{new\_positive\_data} -- List of new, labeled strings.

\item {} 
\textbf{new\_unlabeled\_data} -- List of new, unlabeled strings.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{basic\_extractor() (in module textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.basic_extractor}\pysiglinewithargsret{\code{textblob.classifiers.}\bfcode{basic\_extractor}}{\emph{document}, \emph{train\_set}}{}
A basic document feature extractor that returns a dict indicating
what words in \code{train\_set} are contained in \code{document}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{document} -- The text to extract features from. Can be a string or an iterable.

\item {} 
\textbf{train\_set} (\emph{list}) -- Training data set, a list of tuples of the form
\code{(words, label)}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{contains\_extractor() (in module textblob.classifiers)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.classifiers.contains_extractor}\pysiglinewithargsret{\code{textblob.classifiers.}\bfcode{contains\_extractor}}{\emph{document}}{}
A basic document feature extractor that returns a dict of words that
the document contains.

\end{fulllineitems}



\subsection{Blobber}
\label{api_reference:blobber}\index{BlobberDE (class in textblob\_de.blob)}

\begin{fulllineitems}
\pysiglinewithargsret{\strong{class }\code{textblob\_de.blob.}\bfcode{BlobberDE}}{\emph{tokenizer=None}, \emph{pos\_tagger=None}, \emph{np\_extractor=None}, \emph{analyzer=None}, \emph{parser=None}, \emph{classifier=None}}{}
A factory for TextBlobs that all share the same tagger, tokenizer,
parser, classifier, and np\_extractor.

Usage:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de} \PYG{k+kn}{import} \PYG{n}{BlobberDE}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob\PYGZus{}de.taggers} \PYG{k+kn}{import} \PYG{n}{PatternTagger}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{textblob.tokenizers} \PYG{k+kn}{import} \PYG{n}{PatternTokenizer}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{tb} \PYG{o}{=} \PYG{n}{Blobber}\PYG{p}{(}\PYG{n}{pos\PYGZus{}tagger}\PYG{o}{=}\PYG{n}{PatternTagger}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tokenizer}\PYG{o}{=}\PYG{n}{PatternTokenizer}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob1} \PYG{o}{=} \PYG{n}{tb}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Das ist ein Blob.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob2} \PYG{o}{=} \PYG{n}{tb}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dieser Blob benutzt die selben Tagger und Tokenizer.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{blob1}\PYG{o}{.}\PYG{n}{pos\PYGZus{}tagger} \PYG{o+ow}{is} \PYG{n}{blob2}\PYG{o}{.}\PYG{n}{pos\PYGZus{}tagger}
\PYG{g+go}{True}
\end{Verbatim}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{text} (\emph{str}) -- A string.

\item {} 
\textbf{tokenizer} -- (optional) A tokenizer instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.tokenizers.NLTKPunktTokenizer]{\code{NLTKPunktTokenizer()}}}.

\item {} 
\textbf{np\_extractor} -- (optional) An NPExtractor instance. If \code{None},
defaults to {\hyperref[api_reference:textblob_de.np_extractors.PatternParserNPExtractor]{\code{PatternParserNPExtractor()}}}.

\item {} 
\textbf{pos\_tagger} -- (optional) A Tagger instance. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.taggers.PatternTagger]{\code{PatternTagger}}}.

\item {} 
\textbf{analyzer} -- (optional) A sentiment analyzer. If \code{None}, defaults to
{\hyperref[api_reference:textblob_de.sentiments.PatternAnalyzer]{\code{PatternAnalyzer}}}.

\item {} 
\textbf{classifier} -- (optional) A classifier.

\end{itemize}

\end{description}\end{quote}

\DUspan{versionmodified}{New in version 0.4.0: }(\code{textblob})
\index{\_\_call\_\_() (textblob\_de.blob.BlobberDE method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob_de.blob.BlobberDE.__call__}\pysiglinewithargsret{\bfcode{\_\_call\_\_}}{\emph{text}}{}
Return a new TextBlob object with this Blobber's \code{np\_extractor},
\code{pos\_tagger}, \code{tokenizer}, \code{analyzer}, and \code{classifier}.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A new \code{TextBlob}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{File Formats (from TextBlob main package)}
\label{api_reference:module-textblob.formats}\label{api_reference:file-formats-from-textblob-main-package}\index{textblob.formats (module)}
File formats for training and testing data.

Includes a registry of valid file formats. New file formats can be added to the
registry like so:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{textblob} \PYG{k+kn}{import} \PYG{n}{formats}

\PYG{k}{class} \PYG{n+nc}{PipeDelimitedFormat}\PYG{p}{(}\PYG{n}{formats}\PYG{o}{.}\PYG{n}{DelimitedFormat}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{delimiter} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\textbar{}}\PYG{l+s}{\PYGZsq{}}

\PYG{n}{formats}\PYG{o}{.}\PYG{n}{register}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{psv}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{PipeDelimitedFormat}\PYG{p}{)}
\end{Verbatim}

Once a format has been registered, classifiers will be able to read data files with
that format.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{textblob.classifiers} \PYG{k+kn}{import} \PYG{n}{NaiveBayesAnalyzer}

\PYG{k}{with} \PYG{n+nb}{open}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{training\PYGZus{}data.psv}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{r}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{fp}\PYG{p}{:}
    \PYG{n}{cl} \PYG{o}{=} \PYG{n}{NaiveBayesAnalyzer}\PYG{p}{(}\PYG{n}{fp}\PYG{p}{,} \PYG{n}{format}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{psv}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}
\index{BaseFormat (class in textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.BaseFormat}\pysiglinewithargsret{\strong{class }\code{textblob.formats.}\bfcode{BaseFormat}}{\emph{fp}, \emph{**kwargs}}{}
Interface for format classes. Individual formats can decide on the
composition and meaning of \code{**kwargs}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{fp} (\emph{File}) -- A file-like object.

\end{description}\end{quote}

\DUspan{versionmodified}{Changed in version 0.9.0: }Constructor receives a file pointer rather than a file path.
\index{detect() (textblob.formats.BaseFormat class method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.BaseFormat.detect}\pysiglinewithargsret{\strong{classmethod }\bfcode{detect}}{\emph{stream}}{}
Detect the file format given a filename.
Return True if a stream is this file format.

\DUspan{versionmodified}{Changed in version 0.9.0: }Changed from a static method to a class method.

\end{fulllineitems}

\index{to\_iterable() (textblob.formats.BaseFormat method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.BaseFormat.to_iterable}\pysiglinewithargsret{\bfcode{to\_iterable}}{}{}
Return an iterable object from the data.

\end{fulllineitems}


\end{fulllineitems}

\index{CSV (class in textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.CSV}\pysiglinewithargsret{\strong{class }\code{textblob.formats.}\bfcode{CSV}}{\emph{fp}, \emph{**kwargs}}{}
CSV format. Assumes each row is of the form \code{text,label}.

\begin{Verbatim}[commandchars=\\\{\}]
Today is a good day,pos
I hate this car.,pos
\end{Verbatim}
\index{detect() (textblob.formats.CSV class method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.CSV.detect}\pysiglinewithargsret{\strong{classmethod }\bfcode{detect}}{\emph{stream}}{}
Return True if stream is valid.

\end{fulllineitems}

\index{to\_iterable() (textblob.formats.CSV method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.CSV.to_iterable}\pysiglinewithargsret{\bfcode{to\_iterable}}{}{}
Return an iterable object from the data.

\end{fulllineitems}


\end{fulllineitems}

\index{DelimitedFormat (class in textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.DelimitedFormat}\pysiglinewithargsret{\strong{class }\code{textblob.formats.}\bfcode{DelimitedFormat}}{\emph{fp}, \emph{**kwargs}}{}
A general character-delimited format.
\index{detect() (textblob.formats.DelimitedFormat class method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.DelimitedFormat.detect}\pysiglinewithargsret{\strong{classmethod }\bfcode{detect}}{\emph{stream}}{}
Return True if stream is valid.

\end{fulllineitems}

\index{to\_iterable() (textblob.formats.DelimitedFormat method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.DelimitedFormat.to_iterable}\pysiglinewithargsret{\bfcode{to\_iterable}}{}{}
Return an iterable object from the data.

\end{fulllineitems}


\end{fulllineitems}

\index{JSON (class in textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.JSON}\pysiglinewithargsret{\strong{class }\code{textblob.formats.}\bfcode{JSON}}{\emph{fp}, \emph{**kwargs}}{}
JSON format.

Assumes that JSON is formatted as an array of objects with \code{text} and
\code{label} properties.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{p}{[}
    \PYG{p}{\PYGZob{}}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{text}\PYG{l+s}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Today is a good day.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{label}\PYG{l+s}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{pos}\PYG{l+s}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}\PYG{p}{,}
    \PYG{p}{\PYGZob{}}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{text}\PYG{l+s}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I hate this car.}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{label}\PYG{l+s}{\PYGZdq{}}\PYG{p}{:} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{neg}\PYG{l+s}{\PYGZdq{}}\PYG{p}{\PYGZcb{}}
\PYG{p}{]}
\end{Verbatim}
\index{detect() (textblob.formats.JSON class method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.JSON.detect}\pysiglinewithargsret{\strong{classmethod }\bfcode{detect}}{\emph{stream}}{}
Return True if stream is valid JSON.

\end{fulllineitems}

\index{to\_iterable() (textblob.formats.JSON method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.JSON.to_iterable}\pysiglinewithargsret{\bfcode{to\_iterable}}{}{}
Return an iterable object from the JSON data.

\end{fulllineitems}


\end{fulllineitems}

\index{TSV (class in textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.TSV}\pysiglinewithargsret{\strong{class }\code{textblob.formats.}\bfcode{TSV}}{\emph{fp}, \emph{**kwargs}}{}
TSV format. Assumes each row is of the form \code{text      label}.
\index{detect() (textblob.formats.TSV class method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.TSV.detect}\pysiglinewithargsret{\strong{classmethod }\bfcode{detect}}{\emph{stream}}{}
Return True if stream is valid.

\end{fulllineitems}

\index{to\_iterable() (textblob.formats.TSV method)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.TSV.to_iterable}\pysiglinewithargsret{\bfcode{to\_iterable}}{}{}
Return an iterable object from the data.

\end{fulllineitems}


\end{fulllineitems}

\index{detect() (in module textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.detect}\pysiglinewithargsret{\code{textblob.formats.}\bfcode{detect}}{\emph{fp}, \emph{max\_read=1024}}{}
Attempt to detect a file's format, trying each of the supported
formats. Return the format class that was detected. If no format is
detected, return \code{None}.

\end{fulllineitems}

\index{get\_registry() (in module textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.get_registry}\pysiglinewithargsret{\code{textblob.formats.}\bfcode{get\_registry}}{}{}
Return a dictionary of registered formats.

\end{fulllineitems}

\index{register() (in module textblob.formats)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.formats.register}\pysiglinewithargsret{\code{textblob.formats.}\bfcode{register}}{\emph{name}, \emph{format\_class}}{}
Register a new format.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{name} (\emph{str}) -- The name that will be used to refer to the format, e.g. `csv'

\item {} 
\textbf{format\_class} (\emph{type}) -- The format class to register.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsection{Exceptions (from TextBlob main package)}
\label{api_reference:module-textblob.exceptions}\label{api_reference:exceptions-from-textblob-main-package}\index{textblob.exceptions (module)}\index{MissingCorpusException (in module textblob.exceptions)}

\begin{fulllineitems}
\phantomsection\label{api_reference:textblob.exceptions.MissingCorpusException}\pysigline{\code{textblob.exceptions.}\bfcode{MissingCorpusException}}
alias of \code{MissingCorpusError}

\end{fulllineitems}



\chapter{Project info}
\label{index:project-info}\label{index:id4}

\section{Changelog}
\label{changelog:id1}\label{changelog::doc}\label{changelog:changelog}

\subsection{0.4.0 (17/09/2014)}
\label{changelog:id2}\begin{itemize}
\item {} 
Fixed \href{https://github.com/markuskiller/textblob-de/issues/7}{Issue \#7} (restore \code{textblob\textgreater{}=0.9.0} compatibility)

\item {} 
Depend on \code{nltk3}. Vendorized \code{nltk} was removed in \code{textblob\textgreater{}=0.9.0}

\item {} 
Fixed \code{ImportError} on Python2 (\code{unicodecsv})

\end{itemize}


\subsection{0.3.1 (29/08/2014)}
\label{changelog:id3}\begin{itemize}
\item {} 
Improved \code{PatternParserNPExtractor} (less false positives in verb filter)

\item {} 
Made sure that all keyword arguments with default \code{None} are checked with \code{is not None}

\item {} 
Fixed shortcut to \code{\_pattern.de} in vendorized library

\item {} 
Added \code{Makefile} to facilitate development process

\item {} 
Added docs and API reference

\end{itemize}


\subsection{0.3.0 (14/08/2014)}
\label{changelog:id4}\begin{itemize}
\item {} 
Fixed \href{https://github.com/markuskiller/textblob-de/issues/5}{Issue \#5} (text + space + period)

\end{itemize}


\subsection{0.2.9 (14/08/2014)}
\label{changelog:id5}\begin{itemize}
\item {} 
Fixed tokenization in \code{PatternParser} (if initialized manually, punctuation was not always separated from words)

\item {} 
Improved handling of empty strings (Issue \#3) and of strings containing single punctuation marks (Issue \#4) in \code{PatternTagger} and \code{PatternParser}

\item {} 
Added tests for empty strings and for strings containing single punctuation marks

\end{itemize}


\subsection{0.2.8 (14/08/2014)}
\label{changelog:id6}\begin{itemize}
\item {} 
Fixed \href{https://github.com/markuskiller/textblob-de/issues/3}{Issue \#3} (empty string)

\item {} 
Fixed \href{https://github.com/markuskiller/textblob-de/issues/4}{Issue \#4} (space + punctuation)

\end{itemize}


\subsection{0.2.7 (13/08/2014)}
\label{changelog:id7}\begin{itemize}
\item {} 
Fixed \href{https://github.com/markuskiller/textblob-de/issues/1}{Issue \#1} lemmatization of strings containing a forward slash (\code{/})

\item {} 
Enhancement \href{https://github.com/markuskiller/textblob-de/issues/2}{Issue \#2} use the same rtype as \code{textblob} for sentiment detection.

\item {} 
Fixed tokenization in \code{PatternParserLemmatizer}

\end{itemize}


\subsection{0.2.6 (04/08/2014)}
\label{changelog:id8}\begin{itemize}
\item {} 
Fixed \code{MANIFEST.in} for package data in \code{sdist}

\end{itemize}


\subsection{0.2.5 (04/08/2014)}
\label{changelog:id9}\begin{itemize}
\item {} 
\code{sdist} is non-functional as important files are missing due to a misconfiguration in \code{MANIFEST.in} - does not affect \code{wheels}

\item {} 
Major internal refactoring (but no backwards-incompatible API changes) with the aim of restoring complete compatibility to original \code{pattern\textgreater{}=2.6} library on Python2

\item {} 
Separation of \code{textblob} and \code{pattern} code

\item {} 
On Python2 the vendorized version of \code{pattern.text.de} is only used, if original is not installed (same as \code{nltk})

\item {} 
Made \code{pattern.de.pprint} function and all parser keywords accessible to customise parser output

\item {} 
Access to complete \code{pattern.text.de} API on Python2 and Python3 \code{from textblob\_de.packages import pattern\_de as pd}

\item {} 
\code{tox} passed on all major platforms (Win/Linux/OSX)

\end{itemize}


\subsection{0.2.3 (26/07/2014)}
\label{changelog:id10}\begin{itemize}
\item {} 
Lemmatizer: \code{PatternParserLemmatizer()} extracts lemmata from Parser output

\item {} 
Improved polarity analysis through look-up of lemmatised word forms

\end{itemize}


\subsection{0.2.2 (22/07/2014)}
\label{changelog:id11}\begin{itemize}
\item {} 
Option: Include punctuation in \code{tags}/\code{pos\_tags} properties (\code{b = TextBlobDE(text, tagger=PatternTagger(include\_punc=True))})

\item {} 
Added \code{BlobberDE()} class initialized with German models

\item {} 
\code{TextBlobDE()}, \code{Sentence()}, \code{WordList()} and \code{Word()} classes are now all initialized with German models

\item {} 
Restored complete API compatibility with \code{textblob.tokenizers} module of the main \href{http://textblob.readthedocs.org/en/dev/}{TextBlob} library

\end{itemize}


\subsection{0.2.1 (20/07/2014)}
\label{changelog:id12}\begin{itemize}
\item {} 
Noun Phrase Extraction: \code{PatternParserNPExtractor()} extracts NPs from Parser output

\item {} 
Refactored the way \code{TextBlobDE()} passes on arguments and keyword arguments to individual tools

\item {} 
\emph{Backwards-incompatible}: Deprecate \code{parser\_show\_lemmata=True} keyword in \code{TextBlob()}. Use \code{parser=PatternParser(lemmata=True)} instead.

\end{itemize}


\subsection{0.2.0 (18/07/2014)}
\label{changelog:id13}\begin{itemize}
\item {} 
vastly improved tokenization (\code{NLTKPunktTokenizer} and \code{PatternTokenizer} with tests)

\item {} 
consistent use of specified tokenizer for all tools

\item {} 
\code{TextBlobDE} with initialized default models for German

\item {} 
Parsing (\code{PatternParser}) plus \code{test\_parsers.py}

\item {} 
\textbf{EXPERIMENTAL} implementation of Polarity detection (\code{PatternAnalyzer})

\item {} 
first attempt at extracting German Polarity clues into \code{de-sentiment.xml}

\item {} 
tox tests passing for py26, py27, py33 and py34

\end{itemize}


\subsection{0.1.3 (09/07/2014)}
\label{changelog:id14}\begin{itemize}
\item {} 
First release on PyPI

\end{itemize}


\subsection{0.1.0 - 0.1.2 (09/07/2014)}
\label{changelog:id15}\begin{itemize}
\item {} 
First release on github

\item {} 
A number of experimental releases for testing purposes

\item {} 
Adapted version badges, tests \& travis-ci config

\item {} 
Code adapted from sample extension \href{https://github.com/sloria/textblob-fr}{textblob-fr}

\item {} 
Language specific linguistic resources copied from \href{https://github.com/clips/pattern/tree/master/pattern/text/de}{pattern-de}

\end{itemize}


\section{Credits}
\label{authors:credits}\label{authors::doc}

\subsection{TextBlob Development Lead}
\label{authors:textblob-development-lead}\begin{itemize}
\item {} 
Steven Loria \textless{}\href{mailto:sloria1@gmail.com}{sloria1@gmail.com}\textgreater{}

\end{itemize}


\subsection{textblob-de Author/Maintainer}
\label{authors:textblob-de-author-maintainer}\begin{itemize}
\item {} 
Markus Killer \textless{}\href{mailto:m.killer@langui.ch}{m.killer@langui.ch}\textgreater{}

\end{itemize}


\subsection{Contributors}
\label{authors:contributors}\begin{itemize}
\item {} 
Hocdoc (Issues \#1 - \#5)

\end{itemize}


\section{LICENSE}
\label{license::doc}\label{license:license}\label{license:textblob-de}
\href{http://choosealicense.com/licenses/mit/}{Human readable generic MIT License}

\begin{Verbatim}[commandchars=\\\{\}]
Copyright 2014 Markus Killer

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the \PYGZdq{}Software\PYGZdq{}), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED \PYGZdq{}AS IS\PYGZdq{}, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
\end{Verbatim}


\section{Contributing guidelines}
\label{contributing::doc}\label{contributing:contributing-guidelines}

\subsection{In General}
\label{contributing:in-general}\begin{itemize}
\item {} 
\href{http://www.python.org/dev/peps/pep-0008/}{PEP 8}, when sensible.

\item {} 
Test ruthlessly. Write docs for new features.

\item {} 
Even more important than Test-Driven Development--\emph{Human-Driven Development}.

\end{itemize}


\subsection{In Particular}
\label{contributing:pep-8}\label{contributing:in-particular}

\subsubsection{Questions, Feature Requests, Bug Reports, and Feedback. . .}
\label{contributing:questions-feature-requests-bug-reports-and-feedback}
. . .should all be reported on the \href{https://github.com/markuskiller/textblob-de/issues?state=open}{Github Issue Tracker} . For a nicer interface, check out the \href{https://waffle.io/markuskiller/textblob-de}{textblob-de waffle.io board}.


\subsubsection{Setting Up for Local Development}
\label{contributing:github-issue-tracker}\label{contributing:setting-up-for-local-development}\begin{enumerate}
\item {} 
Fork textblob-de on Github.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} git clone https://github.com/markuskiller/textblob\PYGZhy{}de.git
\PYGZdl{} cd textblob\PYGZhy{}de
\end{Verbatim}

\item {} 
(recommended) Create and activate virtual python environment.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} pip install \PYGZhy{}U virtualenv
\PYGZdl{} virtualenv tb\PYGZhy{}de
\PYGZdl{} \PYGZlt{}activate virtual environment\PYGZgt{}
\end{Verbatim}

\item {} 
Install development requirements and run \code{setupy.py develop}.
(see Makefile help for overview of available
\code{make} targets):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} make develop
\end{Verbatim}

\end{enumerate}


\section{\texttt{make} command}
\label{make_info:make-command}\label{make_info::doc}
This project adopts the \code{Makefile} approach, proposed by Jeff Knupp in his
blog post \href{http://www.jeffknupp.com/blog/2013/08/16/open-sourcing-a-python-project-the-right-way/}{Open Sourcing a Python Project the Right Way }.

On Linux/OSX the \code{make} command should work out-of-the-box:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZdl{} make help
\end{Verbatim}

Shows all available tasks.


\subsection{Using \texttt{make} on Windows}
\label{make_info:using-make-on-windows}
The two \code{Makefile} s in this project should work on all three major platforms.
On Windows, \code{make.exe} included in the \href{http://sourceforge.net/projects/mingw/files/Installer/mingw-get-setup.exe/download}{MinGW/msys}
distribution has been successfully tested. Once \code{msys} is installed
on a Windows system, the \code{path/to/msys/1.0/bin} needs to be added to
the \code{PATH} environment variable.

A good place to update the \code{PATH} variable are the \code{Activate.ps1} or
\code{activate.bat} scripts of a virtual python build environment, created using
\code{virtualenv} (\code{pip install virtualenv}) or \code{pyvenv} (added to Python3.3's standard
library).


\subsubsection{\texttt{Windows PowerShell}}
\label{make_info:windows-powershell}
Add the following line at the end of \code{path\textbackslash{}to\textbackslash{}virtual\textbackslash{}python\textbackslash{}env\textbackslash{}Scripts\textbackslash{}Activate.ps1}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} Add msys binaries to PATH
\PYGZdl{}env:PATH = \PYGZdq{}path\PYGZbs{}to\PYGZbs{}MinGW\PYGZbs{}msys\PYGZbs{}1.0\PYGZbs{}bin;\PYGZdl{}env:PATH\PYGZdq{}
\end{Verbatim}


\subsubsection{Windows \texttt{cmd.exe}}
\label{make_info:windows-cmd-exe}
Add the following line at the end of \code{path\textbackslash{}to\textbackslash{}virtual\textbackslash{}python\textbackslash{}env\textbackslash{}Scripts\textbackslash{}activate.bat}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} Add msys binaries to PATH
set \PYGZdq{}PATH=path\PYGZbs{}to\PYGZbs{}MinGW\PYGZbs{}msys\PYGZbs{}1.0\PYGZbs{}bin;\PYGZpc{}PATH\PYGZpc{}\PYGZdq{}
\end{Verbatim}

Now the \code{make} command should work as documented in \code{\$ make help}.


\section{Project \texttt{Makefile}}
\label{project_makefile:project-makefile}\label{project_makefile::doc}\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
generated: 17 September 2014 \PYGZhy{} 22:26


   Please use \PYGZsq{}make \PYGZlt{}target\PYGZgt{}\PYGZsq{} where where \PYGZlt{}target\PYGZgt{} is one of

   SETUP \PYGZam{} CLEAN
   \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

   install            run \PYGZsq{}python setup.py install\PYGZsq{}
   uninstall          run \PYGZsq{}pip uninstall \PYGZlt{}package\PYGZgt{}\PYGZsq{}
   develop            install links to source files in current Python environment
   reset\PYGZhy{}dev          uninstall all links and console scripts and make clean
   clean              remove all artifacts
   clean\PYGZhy{}build        remove build artifacts
   clean\PYGZhy{}docs         remove documentation build artifacts
   clean\PYGZhy{}pyc          remove Python file artifacts (except in \PYGZsq{}ext\PYGZsq{})
   clean\PYGZhy{}test         remove test artifacts (e.g. \PYGZsq{}htmlcov\PYGZsq{})
   clean\PYGZhy{}logs         remove log artifacts and place empty file in \PYGZsq{}log\PYGZus{}dir\PYGZsq{}

   TESTING
   \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

   autopep8           automatically correct \PYGZsq{}pep8\PYGZsq{} violations
   lint               check style with \PYGZsq{}flake8\PYGZsq{}
   test               run tests quickly with the default Python
   test\PYGZhy{}all           run tests on every Python version with tox
   coverage           check code coverage quickly with the default Python

   PUBLISHING
   \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

   docs               generate Sphinx HTML documentation, including API docs
   docs\PYGZhy{}pdf           generate Sphinx HTML and PDF documentation, including API docs
   sdist              package
   publish            package and upload sdist and universal wheel to PyPI
   register           update README.rst on PyPI
   push\PYGZhy{}github        push all changes to git repository on github.com
   push\PYGZhy{}bitbucket     push all changes to git repository on bitbucket.org
                           \PYGZhy{}\PYGZhy{}\PYGZgt{} include commit message as M=\PYGZsq{}your message\PYGZsq{}

   VARIABLES ACCESSIBLE FROM COMMAND\PYGZhy{}LINE
   \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

   M=\PYGZsq{}your message\PYGZsq{}   mandatory git commit message
   N=\PYGZsq{}package name\PYGZsq{}   specify python package name (optional)
   O=\PYGZsq{}open\textbar{}xdg\PYGZhy{}open\textbar{}start\PYGZsq{}
                           \PYGZhy{}\PYGZhy{}\PYGZgt{} specify platform specific \PYGZsq{}open\PYGZsq{} cmd (optional)
   P=\PYGZsq{}path/to/python\PYGZsq{} specify python executable (optional)
\end{Verbatim}
\end{quote}


\section{Documentation \texttt{Makefile}}
\label{docs_makefile::doc}\label{docs_makefile:documentation-makefile}\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
generated: 17 September 2014 \PYGZhy{} 22:26

   Please use {}`make \PYGZlt{}target\PYGZgt{}\PYGZsq{} where \PYGZlt{}target\PYGZgt{} is one of

   html       to make standalone HTML files
   dirhtml    to make HTML files named index.html in directories
   singlehtml to make a single large HTML file
   pickle     to make pickle files
   json       to make JSON files
   htmlhelp   to make HTML files and a HTML help project
   qthelp     to make HTML files and a qthelp project
   devhelp    to make HTML files and a Devhelp project
   epub       to make an epub
   latex      to make LaTeX files, you can set PAPER=a4 or PAPER=letter
   latexpdf   to make LaTeX files and run them through pdflatex
   latexpdfja to make LaTeX files and run them through platex/dvipdfmx
   text       to make text files
   man        to make manual pages
   texinfo    to make Texinfo files
   info       to make Texinfo files and run them through makeinfo
   gettext    to make PO message catalogs
   changes    to make an overview of all changed/added/deprecated items
   xml        to make Docutils\PYGZhy{}native XML files
   pseudoxml  to make pseudoxml\PYGZhy{}XML files for display purposes
   linkcheck  to check all external links for integrity
   doctest    to run all doctests embedded in the documentation (if enabled)
\end{Verbatim}
\end{quote}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{t}
\item {\texttt{textblob.classifiers}}, \pageref{api_reference:module-textblob.classifiers}
\item {\texttt{textblob.exceptions}}, \pageref{api_reference:module-textblob.exceptions}
\item {\texttt{textblob.formats}}, \pageref{api_reference:module-textblob.formats}
\item {\texttt{textblob\_de.base}}, \pageref{api_reference:module-textblob_de.base}
\item {\texttt{textblob\_de.blob}}, \pageref{api_reference:module-textblob_de.blob}
\item {\texttt{textblob\_de.np\_extractors}}, \pageref{api_reference:module-textblob_de.np_extractors}
\item {\texttt{textblob\_de.parsers}}, \pageref{api_reference:module-textblob_de.parsers}
\item {\texttt{textblob\_de.sentiments}}, \pageref{api_reference:module-textblob_de.sentiments}
\item {\texttt{textblob\_de.taggers}}, \pageref{api_reference:module-textblob_de.taggers}
\item {\texttt{textblob\_de.tokenizers}}, \pageref{api_reference:module-textblob_de.tokenizers}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
