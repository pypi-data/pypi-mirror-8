<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">




<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta property="description" content="Efficient topic modelling of text semantics in Python." />
    <meta property="og:title" content="gensim: topic modelling for humans" />
    <meta property="og:description" content="Efficient topic modelling in Python" />

    
      <title>gensim: models.ldamodelmulticore – Latent Dirichlet Allocation</title>

    
  <link rel="stylesheet" href="../_static/css/style.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/jquery.qtip.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/anythingslider.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/>

    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-24066335-1']);
      _gaq.push(['_trackPageview']);

      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>

  </head>

  <body>
    <div id="topwrap">
      
      <div id="top1">
        <div id="left1">
          <h1 class="h1gensim">
            <img src="../_static/images/logo-gensim_compact.png" alt="gensim logo" title="Gensim - topic modelling for humans" />
          </h1>
        </div>

        <div id="middleright">
          <div id="middle1">
            <div id="gensim"><a href="../index.html"><img src="../_static/images/gensim_compact.png" alt="gensim" title="Gensim home" /></a></div>
            <div id="tagline"><img src="../_static/images/tagline_compact.png" alt="gensim tagline" /></div>
          </div>
          <div id="right1">
            <div class="consulting-banner">
              <h3><a href="http://radimrehurek.com/">Get Expert Help</a></h3>
              <p>• machine learning, NLP, data mining</p>
              <p>• custom SW design, development, optimizations</p>
              <p>• tech trainings &amp; IT consulting</p>
            </div>
          </div>
        </div>
      </div>
     

      
      <div id="menu">
        <div id="indentation1">
          <ul class="menubuttons">
            <li class="menubutton"><a href="../index.html">Home</a></li>
            <li class="menubutton"><a href="../tutorial.html">Tutorials</a></li>
            <li class="menubutton"><a href="../install.html">Install</a></li>
            <li class="menubutton"><a href="../support.html">Support</a></li>
            <li class="menubutton"><a href="../apiref.html">API</a></li>
            <li class="menubutton"><a href="../about.html">About</a></li>
          </ul>
        </div>
      </div>
      

      <div class="clearer"></div>
    </div>

    
  <script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
    URL_ROOT: '../',
    VERSION: '0.10.1',
    COLLAPSE_INDEX: false,
    FILE_SUFFIX: '.html',
    HAS_SOURCE: true
  };
  </script>
    <script type="text/javascript" src="../_static/js/jquery-1.9.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.qtip.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-migrate-1.1.1.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery.anythingslider.min.js"></script>

    
    <div class="document">
      
        <div id="thinbanner">
          <div id="bodythinbanner">
            <span class="h2gensim">models.ldamodelmulticore – Latent Dirichlet Allocation</span>
          </div>
        </div>
        <div class="obsah">
          <div class="obsahwrapper">
            
  <div class="section" id="module-gensim.models.ldamodelmulticore">
<span id="models-ldamodelmulticore-latent-dirichlet-allocation"></span><h1><tt class="xref py py-mod docutils literal"><span class="pre">models.ldamodelmulticore</span></tt> &#8211; Latent Dirichlet Allocation<a class="headerlink" href="#module-gensim.models.ldamodelmulticore" title="Permalink to this headline">¶</a></h1>
<p>Latent Dirichlet Allocation (LDA) in Python, using all cores to parallelize and
speed up model training.</p>
<p>The parallelization uses multiprocessing; in case this doesn&#8217;t work for you for
some reason, try <cite>LdaModel</cite> which is an equivalent, but more straightforward and
single-core implementation.</p>
<p>FIXME wiki timings</p>
<p>This module allows both LDA model estimation from a training corpus and inference of topic
distribution on new, unseen documents. The model can also be updated with new documents
for online training.</p>
<p>The core estimation code is based on the <cite>onlineldavb.py</cite> script by M. Hoffman <a class="footnote-reference" href="#id2" id="id1">[1]</a>, see
<strong>Hoffman, Blei, Bach: Online Learning for Latent Dirichlet Allocation, NIPS 2010.</strong></p>
<p>The algorithm:</p>
<ul class="simple">
<li>is <strong>streamed</strong>: training documents may come in sequentially, no random access required,</li>
<li>runs in <strong>constant memory</strong> w.r.t. the number of documents: size of the
training corpus does not affect memory footprint, can process corpora larger than RAM, and</li>
<li>is <strong>distributed</strong>: makes use of a cluster of machines, if available, to
speed up model estimation.</li>
</ul>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td><a class="reference external" href="http://www.cs.princeton.edu/~mdhoffma">http://www.cs.princeton.edu/~mdhoffma</a></td></tr>
</tbody>
</table>
<dl class="class">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore">
<em class="property">class </em><tt class="descclassname">gensim.models.ldamodelmulticore.</tt><tt class="descname">LdaModelMulticore</tt><big>(</big><em>corpus=None</em>, <em>num_topics=100</em>, <em>id2word=None</em>, <em>workers=7</em>, <em>chunksize=2000</em>, <em>passes=1</em>, <em>batch=False</em>, <em>alpha='symmetric'</em>, <em>eta=None</em>, <em>decay=0.5</em>, <em>eval_every=10</em>, <em>iterations=50</em>, <em>gamma_threshold=0.001</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore" title="Permalink to this definition">¶</a></dt>
<dd><p>The constructor estimates Latent Dirichlet Allocation model parameters based
on a training corpus:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LdaModelMulticore</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>You can then infer topic distributions on new, unseen documents, with</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">doc_lda</span> <span class="o">=</span> <span class="n">lda</span><span class="p">[</span><span class="n">doc_bow</span><span class="p">]</span>
</pre></div>
</div>
<p>The model can be updated (trained) with new documents via</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">other_corpus</span><span class="p">)</span>
</pre></div>
</div>
<p>Model persistency is achieved through its <cite>load</cite>/<cite>save</cite> methods.</p>
<p>If given, start training from the iterable <cite>corpus</cite> straight away. If not given,
the model is left untrained (presumably because you want to call <cite>update()</cite> manually).</p>
<p><cite>num_topics</cite> is the number of requested latent topics to be extracted from
the training corpus.</p>
<p><cite>id2word</cite> is a mapping from word ids (integers) to words (strings). It is
used to determine the vocabulary size, as well as for debugging and topic
printing.</p>
<p><cite>workers</cite> is the number of extra processes to use for parallelization. Use
all available cores by default.</p>
<p>If <cite>batch</cite> is not set, perform online training by updating the model once
every <cite>workers * chunksize</cite> documents (online training). Otherwise,
run batch LDA, updating model only once at the end of each full corpus pass.</p>
<p><cite>alpha</cite> and <cite>eta</cite> are hyperparameters that affect sparsity of the document-topic
(theta) and topic-word (lambda) distributions. Both default to a symmetric
1.0/num_topics prior.</p>
<p><cite>alpha</cite> can be set to an explicit array = prior of your choice. It also
support special values of &#8216;asymmetric&#8217; and &#8216;auto&#8217;: the former uses a fixed
normalized asymmetric 1.0/topicno prior, the latter learns an asymmetric
prior directly from your data.</p>
<p><a href="#id3"><span class="problematic" id="id4">`</span></a>eta&#8217; can be a scalar for a symmetric prior over topic/word
distributions, or a matrix of shape num_topics x num_words,
which can be used to impose asymmetric priors over the word
distribution on a per-topic basis. This may be useful if you
want to seed certain topics with particular words by boosting
the priors for those words.</p>
<p>Calculate and log perplexity estimate from the latest mini-batch once every
<cite>eval_every</cite> documents. Set to None to disable perplexity estimation (faster).</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span> <span class="o">=</span> <span class="n">LdaModelMulticore</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">id2word</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c"># train model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">lda</span><span class="p">[</span><span class="n">doc_bow</span><span class="p">])</span> <span class="c"># get topic probability distribution for a document</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lda</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">corpus2</span><span class="p">)</span> <span class="c"># update the LDA model with additional documents</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">lda</span><span class="p">[</span><span class="n">doc_bow</span><span class="p">])</span>
</pre></div>
</div>
<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.bound">
<tt class="descname">bound</tt><big>(</big><em>corpus</em>, <em>gamma=None</em>, <em>subsample_ratio=1.0</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.bound" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the variational bound of documents from <cite>corpus</cite>:
E_q[log p(corpus)] - E_q[log q(corpus)]</p>
<p><cite>gamma</cite> are the variational parameters on topic weights for each <cite>corpus</cite>
document (=2d matrix=what comes out of <cite>inference()</cite>).
If not supplied, will be inferred from the model.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.clear">
<tt class="descname">clear</tt><big>(</big><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Clear model state (free up some memory). Used in the distributed algo.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.do_estep">
<tt class="descname">do_estep</tt><big>(</big><em>chunk</em>, <em>state=None</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.do_estep" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform inference on a chunk of documents, and accumulate the collected
sufficient statistics in <cite>state</cite> (or <cite>self.state</cite> if None).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.do_mstep">
<tt class="descname">do_mstep</tt><big>(</big><em>rho</em>, <em>other</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.do_mstep" title="Permalink to this definition">¶</a></dt>
<dd><p>M step: use linear interpolation between the existing topics and
collected sufficient statistics in <cite>other</cite> to update the topics.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.inference">
<tt class="descname">inference</tt><big>(</big><em>chunk</em>, <em>collect_sstats=False</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a chunk of sparse document vectors, estimate gamma (parameters
controlling the topic weights) for each document in the chunk.</p>
<p>This function does not modify the model (=is read-only aka const). The
whole input chunk of document is assumed to fit in RAM; chunking of a
large corpus must be done earlier in the pipeline.</p>
<p>If <cite>collect_sstats</cite> is True, also collect sufficient statistics needed
to update the model&#8217;s topic-word distributions, and return a 2-tuple
<cite>(gamma, sstats)</cite>. Otherwise, return <cite>(gamma, None)</cite>. <cite>gamma</cite> is of shape
<cite>len(chunk) x self.num_topics</cite>.</p>
<p>Avoids computing the <cite>phi</cite> variational parameter directly using the
optimization presented in <strong>Lee, Seung: Algorithms for non-negative matrix factorization, NIPS 2001</strong>.</p>
</dd></dl>

<dl class="classmethod">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.load">
<em class="property">classmethod </em><tt class="descname">load</tt><big>(</big><em>fname</em>, <em>*args</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Load a previously saved object from file (also see <cite>save</cite>).</p>
<p>Large arrays are mmap&#8217;ed back as read-only (shared memory).</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.save">
<tt class="descname">save</tt><big>(</big><em>fname</em>, <em>*args</em>, <em>**kwargs</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the model to file.</p>
<p>Large internal arrays may be stored into separate files, with <cite>fname</cite> as prefix.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.show_topics">
<tt class="descname">show_topics</tt><big>(</big><em>num_topics=10</em>, <em>num_words=10</em>, <em>log=False</em>, <em>formatted=True</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.show_topics" title="Permalink to this definition">¶</a></dt>
<dd><p>For <cite>num_topics</cite> number of topics, return <cite>num_words</cite> most significant words
(10 words per topic, by default).</p>
<p>The topics are returned as a list &#8211; a list of strings if <cite>formatted</cite> is
True, or a list of (probability, word) 2-tuples if False.</p>
<p>If <cite>log</cite> is True, also output this result to log.</p>
<p>Unlike LSA, there is no natural ordering between the topics in LDA.
The returned <cite>num_topics &lt;= self.num_topics</cite> subset of all topics is therefore
arbitrary and may change between two LDA training runs.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.update">
<tt class="descname">update</tt><big>(</big><em>corpus</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Train the model with new documents, by EM-iterating over <cite>corpus</cite> until
the topics converge (or until the maximum number of allowed iterations
is reached). <cite>corpus</cite> must be an iterable (repeatable stream of documents),</p>
<p>The E-step is distributed into the several processes.</p>
<p>This update also supports updating an already trained model (<cite>self</cite>)
with new documents from <cite>corpus</cite>; the two models are then merged in
proportion to the number of old vs. new documents. This feature is still
experimental for non-stationary input streams.</p>
<p>For stationary input (no topic drift in new documents), on the other hand,
this equals the online update of Hoffman et al. and is guaranteed to
converge for any <cite>decay</cite> in (0.5, 1.0&gt;.</p>
</dd></dl>

<dl class="method">
<dt id="gensim.models.ldamodelmulticore.LdaModelMulticore.update_alpha">
<tt class="descname">update_alpha</tt><big>(</big><em>gammat</em>, <em>rho</em><big>)</big><a class="headerlink" href="#gensim.models.ldamodelmulticore.LdaModelMulticore.update_alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Update parameters for the Dirichlet prior on the per-document
topic weights <cite>alpha</cite> given the last <cite>gammat</cite>.</p>
<p>Uses Newton&#8217;s method, described in <strong>Huang: Maximum Likelihood Estimation of Dirichlet Distribution Parameters.</strong> (<a class="reference external" href="http://www.stanford.edu/~jhuang11/research/dirichlet/dirichlet.pdf">http://www.stanford.edu/~jhuang11/research/dirichlet/dirichlet.pdf</a>)</p>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      

      <div class="clearer"></div>
    </div>
    

    
    <div id="footer">
      <div id="footerwrapper">
        <div id="footerleft">
          <img src="../_static/images/logo-gensim.png" class="smallerlogo" alt="smaller gensim logo" />
          <a href="../index.html"><img src="../_static/images/gensim-footer.png" alt="gensim footer image" title="Gensim home" /></a>

          <div class="copyright">
            &copy; Copyright 2009-now, <a href="mailto:radimrehurek@seznam.cz" style="color:white"> Radim Řehůřek</a>
            <br />
              Last updated on Sep 14, 2014.
          </div>
        </div>

        <div id="footermiddleright">
          <div id="footermiddle">
            <ul class="navigation">
              <li><a href="../index.html">
                Home
              </a></li>
              <li>|</li>
              <li><a href="../tutorial.html">
                Tutorials
              </a></li>
              <li>|</li>
              <li><a href="../install.html">
                Install
              </a></li>
              <li>|</li>
              <li><a href="../support.html">
                Support
              </a></li>
              <li>|</li>
              <li><a href="../apiref.html">
                API
              </a></li>
              <li>|</li>
              <li><a href="../about.html">
                About
              </a></li>
            </ul>

            <div class="tweetodsazeni">
              <div class="tweet">
                <a href="https://twitter.com/radimrehurek" target="_blank" style="color: white">Tweet @RadimRehurek</a>
              </div>
            </div>

          </div>

          <div id="footerright">
            <div class="footernadpis">
              Support:
            </div>
            <div class="googlegroupsodsazeni">
              <a href="https://groups.google.com/group/gensim" class="googlegroups">
                Stay informed via gensim mailing list:
              </a>

              <form action="http://groups.google.com/group/gensim/boxsubscribe">
                <input type="text" name="email" placeholder="your@email.com" size="28" />
                <input type="submit" name="sub" value="Subscribe" />
              </form>

            </div>

            <div class="addthis_toolbox addthis_default_style addthis_32x32_style"
                addthis:title="#gensim"
                addthis:description="Efficient Topic Modelling in Python"
                style="margin:20px 0 0 0">
              <a class="addthis_button_preferred_1"></a>
              <a class="addthis_button_preferred_2"></a>
              <a class="addthis_button_preferred_3"></a>
              <a class="addthis_button_preferred_4"></a>
              <a class="addthis_button_compact"></a>
              <a class="addthis_counter addthis_bubble_style"></a>
            </div>
          </div>

        </div>
      </div>
    </div>
    

    <script type="text/javascript">
      (function() {
      var at = document.createElement('script'); at.type = 'text/javascript'; at.async = true;
      at.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 's7.addthis.com/js/250/addthis_widget.js#pubid=ra-4d738b9b1d31ccbd';
      var sat = document.getElementsByTagName('script')[0]; sat.parentNode.insertBefore(at, sat);
      })();
    </script>

  </body>
</html>