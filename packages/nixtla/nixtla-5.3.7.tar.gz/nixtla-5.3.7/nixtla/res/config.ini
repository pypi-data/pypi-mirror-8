[Modules]
TrackingModule = nixtla.tracking.interface.ITrackingModule
SegmentationModule = nixtla.segmentation.interface.ISegmentationModule  
ModellingModule = nixtla.modelling.interface.IModellingModule
VerificationModule = nixtla.verification.interface.IVerificationModule

[Pipeline]
workflow = [(TrackingModule, SegmentationModule), 
            (SegmentationModule, ModellingModule),
            (ModellingModule, VerificationModule)]
entry_module = TrackingModule
annotator = nixtla.core.annotation.elan.ElanAnnotation
results_file_path = ~/results.eaf
annotation_video_path = ./res/SignerA.mp4

[TrackingModule]
implementedBy =  nixtla.tracking.text_based.implementation.TrackingModule
#tracking_files = [./res/TrackingResultA.txt,
#                             ./res/TrackingResultB.txt]
tracking_files = [./res/TrackingResultA.txt]
raw_video_file = ./res/SignerA.mp4
corpus_processing_class = nixtla.core.tools.corpora.dictasign.DictaSignSpecific
rounded = True

[SegmentationModule]
implementedBy =  nixtla.segmentation.handspeed_based.implementation.SegmentationModule
analysis_window = 5

# With respect to which articulators we are cutting segments
articulators = [right_hand, left_hand]

# Speed threshold to use in segmentation
#speed_threshold = 6.0
speed_threshold = 1.86

# maximum noise level of tracker 1.0
noise_threshold = 0.5 
small_movement_threshold = 3.0

# Calculated on a long movement
long_threshold = 9.0 

# Calculated on a fast, short movement
short_threshold = 16.0 

# Between noise_threshold and long_threshold, 
# movements can have intention or not, so we can try to see them
# as trills or else use knowledge to discard them.

[ModellingModule]
implementedBy =  nixtla.modelling.channel_based.implementation.ModellingModule
history_verification_length = 30

# We will create histories for each articulator of interest
articulators = [right_hand, left_hand]
ruleset = ./res/rules.ini

[VerificationModule]
implementedBy =  nixtla.verification.simple_method.implementation.VerificationModule